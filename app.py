import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
from scipy.interpolate import griddata
# å°è¯•å¯¼å…¥ Visualizerï¼Œå¦‚æœ src æœªåœ¨è·¯å¾„ä¸­åˆ™æ·»åŠ 
import sys
if "src" not in sys.path:
    sys.path.append(os.path.join(os.path.dirname(__file__), "src"))
try:
    from src.visualizer import Visualizer
except ImportError:
    # Fallback if running from src directory or other structure
    from visualizer import Visualizer

# 1. åŸºç¡€é…ç½®
st.set_page_config(
    layout="wide", 
    page_title="åœŸçŸ³åæ•°å­—å­ªç”Ÿå¹³å°",
    page_icon="ğŸŒŠ"
)

# 2. å¼ºåˆ¶æ·±è‰²æ¨¡å¼ & å·¥ä¸šé£ CSS
st.markdown("""
<style>
    /* å…¨å±€èƒŒæ™¯è®¾ä¸ºæ·±ç° */
    .stApp {
        background-color: #0E1117;
    }
    
    /* ä¾§è¾¹æ è®¾ä¸ºåŠé€æ˜é»‘ï¼Œå¢åŠ ç£¨ç ‚æ„Ÿ */
    [data-testid="stSidebar"] {
        background-color: rgba(20, 20, 30, 0.9);
        border-right: 1px solid #333;
    }
    
    /* å­—ä½“é¢œè‰²ä¼˜åŒ– */
    .stMarkdown, .stText, h1, h2, h3 {
        color: #E0E0E0 !important;
    }
    
    /* æ»‘å—æ ·å¼å¾®è°ƒ (å¯é€‰) */
    .stSlider > div > div > div > div {
        background-color: #00ADB5;
    }
    
    /* æŒ‡æ ‡å¡ç‰‡æ ·å¼ */
    div[data-testid="metric-container"] {
        background-color: #1E212B;
        padding: 15px;
        border-radius: 8px;
        border: 1px solid #333;
    }
</style>
""", unsafe_allow_html=True)

# æ•°æ®åŠ è½½å‡½æ•°
@st.cache_data
def load_data():
    # åŠ¨æ€è·å–è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_path = os.path.join(current_dir, "data", "processed", "master_dataset.csv")
    node_path = os.path.join(current_dir, "data", "raw", "Node.xlsx") # éœ€è¦èŠ‚ç‚¹åæ ‡ç”¨äº3Dæ’å€¼
    
    if not os.path.exists(data_path):
        st.error(f"æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {data_path}")
        return None, None
        
    df = pd.read_csv(data_path)
    
    # åŠ è½½èŠ‚ç‚¹åæ ‡ (Master Dataset å¯èƒ½æœ‰äº›æ—¶é—´æ­¥ç¼ºåæ ‡ï¼Œæˆ–è€…ä¸ºäº†3Dæ’å€¼æ–¹ä¾¿ç›´æ¥è¯»Nodeè¡¨)
    # å…¶å® master_dataset å·²ç»åŒ…å« X, Y åˆ—ï¼Œå¯ä»¥ç›´æ¥ç”¨
    # ä½†ä¸ºäº†æ„å»º Visualizerï¼Œæˆ‘ä»¬éœ€è¦ node_df
    # æˆ‘ä»¬å¯ä»¥ä» df ä¸­æå–å”¯ä¸€çš„ node_df
    node_df = df[['Node_ID', 'X', 'Y']].drop_duplicates()
    
    return df, node_df

# åŠ è½½æ•°æ®
df, node_df = load_data()
viz = Visualizer(node_df) if node_df is not None else None

# 3. ä¾§è¾¹æ  (Control Panel)
with st.sidebar:
    st.title("ğŸ›ï¸ ç›‘æµ‹æ§åˆ¶å°")
    st.markdown("---")
    
    # å…¨å±€æ—¶é—´è½´
    current_time = st.slider(
        "â±ï¸ æ—¶é—´å›æº¯ (Time Machine)", 
        min_value=30, 
        max_value=1500, 
        step=30,
        value=1500,
        help="æ‹–åŠ¨æ»‘å—å›æº¯å†å²å˜å½¢çŠ¶æ€"
    )
    
    st.markdown("### ğŸ”ï¸ åœºæ™¯å‚æ•° (HST æ¨¡å‹ä»¿çœŸ)")
    st.info("åŸºäº Hydrostatic-Seasonal-Time ç†è®º")
    st.latex(r"\delta = a_0 + a_1 H + a_2 H^2 + b_1 T + c_1 \theta")
    
    water_level = st.slider("ğŸŒŠ ä¸Šæ¸¸æ°´ä½ H (m)", 140.0, 180.0, 165.0, step=0.5)
    temperature = st.slider("ğŸŒ¡ï¸ ç¯å¢ƒæ¸©åº¦ T (Â°C)", -10.0, 40.0, 25.0, step=1.0)
    
    # --- HST æ­£å‘æ¨æ¼”é€»è¾‘ ---
    # å®šä¹‰åŸºå‡†å‚æ•° (Reference State)
    H0, T0 = 165.0, 25.0
    
    # HST è®¡ç®—å·²ç§»è‡³ä¸»æµç¨‹ä»¥ç¡®ä¿å…¨å±€ç”Ÿæ•ˆ
    
    # æ¨¡å¼åˆ‡æ¢ï¼šçœŸå®ç‰©ç†æ¨¡å¼ vs ç­”è¾©æ¼”ç¤ºæ¨¡å¼
    use_demo_mode = st.checkbox("ğŸ”¥ å¼€å¯çµæ•åº¦å¢å¼º (Demo Mode)", value=True, help="é€‰ä¸­ï¼šæ”¾å¤§ç‰©ç†ç³»æ•°ä»¥å±•ç¤ºè¶‹åŠ¿ï¼›å–æ¶ˆï¼šä½¿ç”¨çœŸå®å¾®å°å˜å½¢é‡")

    # --- HST æ­£å‘æ¨æ¼”é€»è¾‘ (æ”¾åˆ° Sidebar å†…éƒ¨ä»¥å®ç°å®æ—¶é¢„è§ˆï¼Œä¸”å˜é‡è‡ªåŠ¨å…¨å±€å¯è§) ---
    if use_demo_mode:
        k_H1, k_H2 = -0.5, -0.01 
        k_T = 0.5
    else:
        k_H1, k_H2 = -0.01, -0.0002
        k_T = 0.01

    # å®šä¹‰åŸºå‡†å‚æ•° (Reference State)
    H0, T0 = 165.0, 25.0
    
    # è®¡ç®— HST å¢é‡ (Delta in mm)
    delta_H = k_H1 * (water_level - H0) + k_H2 * (water_level - H0)**2
    delta_T = k_T * (temperature - T0)
    hst_total_delta = delta_H + delta_T

    st.markdown("---")
    st.caption(f"ä»¿çœŸé¢„è§ˆ: é¢„è®¡å½±å“ KPI")
    
    st.markdown("---")
    st.caption(f"HST ä»¿çœŸå¢é‡: **{hst_total_delta:+.2f} mm**")
    if abs(hst_total_delta) > 0.1:
        st.write(f"- æ°´å‹å› å­: {delta_H:+.2f} mm")
        st.write(f"- çƒ­èƒ€å› å­: {delta_T:+.2f} mm")
    
    st.markdown("---")
    st.markdown("---")
    st.info(f"å½“å‰ä»¿çœŸæ­¥: **{current_time}**")

# --- HST è®¡ç®—é€»è¾‘å·²ç§»å› Sidebar ---
# å˜é‡ hst_total_delta åœ¨æ­¤å¤„ä¾ç„¶å¯ç”¨ (Python ä½œç”¨åŸŸç‰¹æ€§)

# 4. ä¸»å¸ƒå±€å®¹å™¨
st.title("ğŸŒŠ åŸºäºæ•°å­—å­ªç”Ÿçš„åœŸçŸ³åå…¨ç”Ÿå‘½å‘¨æœŸæ™ºæ…§ç›‘æµ‹ç³»ç»Ÿ")
st.markdown("##### Digital Twin System for Earth-Rock Dam Lifecycle Monitoring")
st.caption("æ ¸å¿ƒç®—æ³•: Stacking Ensemble + BiLSTM | ä»¿çœŸå¼•æ“: HST Model (Ref: [WHU-Wzj/Dam-deformation-prediction](https://github.com/WHU-Wzj/Dam-deformation-prediction))")

# 3:1 åˆ†æ 
col_main, col_kpi = st.columns([3, 1])

with col_main:
    st.markdown("### ğŸ—ºï¸ æ ¸å¿ƒç›‘æµ‹è§†å›¾ (Core Monitor View)")
    
    if df is not None:
        tab1, tab2 = st.tabs(["2D ç­‰å€¼çº¿è§†å›¾", "3D å…¨æ¯åœ°å½¢è§†å›¾"])
        
        with tab1:
            st.caption("å®æ—¶å˜å½¢ç­‰å€¼çº¿ (Deformation Contour)")
            fig_2d = viz.plot_dam_contour(df, current_time, value_col='Total_Settlement')
            if fig_2d:
                st.plotly_chart(fig_2d, use_container_width=True)
            else:
                st.warning(f"æ—¶é—´æ­¥ {current_time} æ— æ•°æ®")
                
        with tab2:
            st.caption("3D å…¨æ¯åœ°å½¢ (Holographic Terrain)")
            # 3D ç»˜å›¾é€»è¾‘
            step_df = df[df['Time_Step'] == current_time]
            if not step_df.empty:
                x = step_df['X'].values
                y = step_df['Y'].values
                # æ²‰é™é€šå¸¸æ˜¯è´Ÿå€¼ï¼Œä¸ºäº†3Dæ˜¾ç¤ºæ•ˆæœï¼Œæˆ‘ä»¬å¯ä»¥å–ç»å¯¹å€¼æˆ–è€…ç›´æ¥ç”¨
                # ä»»åŠ¡ä¹¦è¦æ±‚: Z è½´æ”¾å¤§ 100 å€
                z = step_df['Total_Settlement'].values
                
                # æ’å€¼ç½‘æ ¼
                grid_x, grid_y = np.mgrid[min(x):max(x):100j, min(y):max(y):100j]
                grid_z = griddata((x, y), z, (grid_x, grid_y), method='cubic')
                
                # 3D Surface Plot
                fig_3d = go.Figure(data=[go.Surface(
                    z=grid_z * 100, # Zè½´æ”¾å¤§100å€
                    x=grid_x, 
                    y=grid_y,
                    colorscale='Turbo',
                    lighting=dict(roughness=0.5, ambient=0.5, diffuse=0.5), # å…‰ç…§æ•ˆæœ
                    lightposition=dict(x=0, y=0, z=2000) # å…‰æºä½ç½®
                )])
                
                fig_3d.update_layout(
                    title=f'3D Terrain (x100) - T={current_time}',
                    scene=dict(
                        xaxis_title='X',
                        yaxis_title='Y',
                        zaxis_title='Settlement',
                        aspectratio=dict(x=1, y=1, z=0.5)
                    ),
                    margin=dict(l=0, r=0, b=0, t=30),
                    height=500
                )
                st.plotly_chart(fig_3d, use_container_width=True)
            else:
                st.warning("å½“å‰æ—¶é—´æ­¥æ— æ•°æ®ç”¨äº 3D å»ºæ¨¡")
    else:
        st.error("æ•°æ®åŠ è½½å¤±è´¥ã€‚")

with col_kpi:
    st.markdown(f"### ğŸ“Š å…³é”®æŒ‡æ ‡ (T={current_time})")
    
    # åŠ¨æ€è®¡ç®— KPI
    if df is not None:
        current_step_df = df[df['Time_Step'] == current_time]
        
        # å°è¯•è·å–ä¸Šä¸€æœˆæ•°æ®è®¡ç®—é€Ÿç‡ (Time Machine 30å¤©æ­¥é•¿)
        prev_time = current_time - 30
        prev_step_df = df[df['Time_Step'] == prev_time] if prev_time > 0 else pd.DataFrame()
        
        if not current_step_df.empty:
            # 1. æœ€å¤§æ²‰é™
            min_val = current_step_df['Total_Settlement'].min() # è´Ÿå€¼ï¼Œè¶Šå°æ²‰é™è¶Šå¤§
            max_settle_mm = min_val * 1000
            max_node = current_step_df.loc[current_step_df['Total_Settlement'].idxmin(), 'Node_ID']
            
            # 2. å¹³å‡å˜å½¢é€Ÿç‡ (mm/day)
            avg_rate_str = "--"
            avg_rate_delta = None
            if not prev_step_df.empty:
                # ç®€å•è®¡ç®—æ•´åå¹³å‡æ²‰é™å·®
                raw_curr_mean = current_step_df['Total_Settlement'].mean() * 1000
                prev_mean = prev_step_df['Total_Settlement'].mean() * 1000
                
                # åŸå§‹é€Ÿç‡ (Historical)
                raw_rate = (raw_curr_mean - prev_mean) / 30.0
                
                # å åŠ  HST æ•ˆåº”åçš„é€Ÿç‡ (Simulated)
                # å‡è®¾ HST å˜å½¢æ˜¯"çªå‘"çš„ï¼Œå°†å…¶è®¡å…¥å½“å‰çŠ¶æ€
                sim_curr_mean = raw_curr_mean + hst_total_delta
                
                # âš ï¸ å…³é”®ä¿®æ”¹: ä¸ºäº†è®©ç”¨æˆ·æ˜æ˜¾çœ‹åˆ°é€Ÿç‡å˜åŒ–ï¼Œæˆ‘ä»¬å°† HST å¢é‡è§†ä¸º"ç¬æ—¶å“åº”", 
                # ä½†ä¸ºäº†ç»´æŒå•ä½(mm/d)çš„ç‰©ç†æ„ä¹‰ï¼Œæˆ‘ä»¬å‡è®¾è¿™ä¸ªå¢é‡æ˜¯åœ¨æœ€å 1 å¤©å‘ç”Ÿçš„ï¼Œæˆ–è€…å¹³å‡åˆ†æ‘Šåˆ° 30 å¤©
                # è¿™é‡Œé‡‡ç”¨å¹³å‡åˆ†æ‘Šï¼Œä½†å› ä¸º hst_delta å¯èƒ½å¾ˆå¤§ï¼Œé™¤ä»¥ 30 åä¾ç„¶å¯è§
                sim_rate = (sim_curr_mean - prev_mean) / 30.0
                
                avg_rate_str = f"{sim_rate:.3f} mm/d"
                
                # å˜åŒ–ç‡æ˜¾ç¤º
                if abs(prev_mean) > 1e-6:
                     # å¯¹æ¯” "æœ‰ä»¿çœŸ vs æ— ä»¿çœŸ" çš„å˜åŒ–ï¼Œæˆ–è€… "å½“å‰ vs è¿‡å»"
                     # è¿™é‡Œæ˜¾ç¤ºç›¸å¯¹äº T-30 çš„å˜åŒ–ç™¾åˆ†æ¯”
                     rate_diff_pct = (sim_rate / abs(prev_mean)) * 100 
                     avg_rate_delta = f"{rate_diff_pct:.1f}%"
            
            # 3. å¥åº·åº¦è¯„åˆ† (åŸºäº HST ä¿®æ­£åçš„æ²‰é™)
            # åŸå§‹ç›‘æµ‹å€¼ + HST ä»¿çœŸå¢é‡ = æœ€ç»ˆæ¨æ¼”æ²‰é™
            final_settle_mm = max_settle_mm + hst_total_delta
            
            # å¥åº·åº¦è®¡ç®—
            health_score = max(0, 100 - abs(final_settle_mm) * 0.2)
            
            # çŠ¶æ€åˆ¤å®š
            if health_score > 85:
                status_icon, status_text = "ğŸŸ¢", "å¥åº· (Stable)"
            elif health_score > 60:
                status_icon, status_text = "ğŸŸ¡", "æ³¨æ„ (Warning)"
            else:
                status_icon, status_text = "ğŸ”´", "å±é™© (Critical)"
            
            # è®¡ç®—æ²‰é™å¢é‡ä½œä¸º Delta (ç›¸å¯¹äº T-30)
            pct_change = "0%"
            if not prev_step_df.empty:
                prev_min_mm = prev_step_df['Total_Settlement'].min() * 1000
                real_diff = abs(max_settle_mm) - abs(prev_min_mm)
                
                # æ˜¾å¼æ˜¾ç¤ºç»„æˆ
                if abs(hst_total_delta) > 0.01:
                    pct_change = f"ç›‘æµ‹ {real_diff:+.1f} | ä»¿çœŸ {hst_total_delta:+.1f}"
                else:
                    pct_change = f"ç›‘æµ‹å¢é‡ {real_diff:+.1f}"
            
            st.metric("ğŸš¨ æœ€å¤§æ²‰é™ç‚¹ (Node)", f"{int(max_node)}", f"{final_settle_mm:.2f} mm", delta_color="inverse", help=f"åŸå§‹è§‚æµ‹: {max_settle_mm:.2f} + HSTä»¿çœŸ: {hst_total_delta:.2f}")
            st.metric("ğŸ“‰ å¹³å‡å˜å½¢é€Ÿç‡ (Rate)", avg_rate_str, avg_rate_delta, help=f"å«ä»¿çœŸå¢é‡çš„ 30å¤©å¹³å‡é€Ÿç‡\n(HST Delta: {hst_total_delta:.2f} mm)")
            st.metric(f"ğŸ›¡ï¸ å¤§åå¥åº·åº¦ ({status_text})", f"{health_score:.1f} åˆ†", pct_change, delta_color="normal")
            
        else:
            st.info("ç­‰å¾…æ•°æ®...")
    
    st.markdown("---")
    st.markdown("#### ğŸš€ ç³»ç»ŸçŠ¶æ€")
    if abs(hst_total_delta) > 0.1:
        st.info(f"ğŸ§ª HST ä»¿çœŸç”Ÿæ•ˆä¸­\n\n- æ°´ä½/æ¸©åº¦å¯¼è‡´å˜å½¢: **{hst_total_delta:+.2f} mm**\n- å…³é”®æŒ‡æ ‡å·²å®æ—¶ä¿®æ­£")
    else:
        st.success("âœ… å¤„äºåŸºå‡†ç¯å¢ƒçŠ¶æ€ (æ— é¢å¤–ä»¿çœŸå¢é‡)")

    # --- ä¿®å¤æŠ¥å‘Šç”Ÿæˆå™¨å˜é‡å bug ---
    # (æ­¤æ®µé€»è¾‘å®é™…åœ¨ Sidebar åº•éƒ¨ï¼Œä½†ä¸ºäº†æ–¹ä¾¿é˜…è¯»é€»è¾‘ï¼Œæˆ‘ä»¬ç¡®è®¤å˜é‡åä¸€è‡´æ€§)
    # report_section_vars = {'max_settle_mm': final_settle_mm, ...}


# --- åº•éƒ¨: AI é¢„æµ‹å®éªŒå®¤ ---
st.markdown("---")
with st.expander("ğŸ¤– æ··åˆä¸“å®¶é¢„æµ‹ç³»ç»Ÿ (Hybrid Expert System)", expanded=True):
    st.markdown("##### The Lab: åŸºäº Stacking é›†æˆå­¦ä¹ ä¸ Attention-BiLSTM çš„å¤šæ¨¡æ€é¢„æµ‹")
    
    # ä»æ•°æ®åº“åŠ¨æ€åŠ è½½æ‰€æœ‰èŠ‚ç‚¹
    @st.cache_data
    def load_all_nodes():
        import sqlite3
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data", "processed", "predictions.db")
        if os.path.exists(db_path):
            conn = sqlite3.connect(db_path)
            nodes = conn.execute('SELECT DISTINCT node_id, x, y FROM predictions ORDER BY node_id').fetchall()
            conn.close()
            return {int(n[0]): (float(n[1]), float(n[2])) for n in nodes}
        return {}
    
    all_nodes = load_all_nodes()
    
    # èŠ‚ç‚¹é€‰æ‹©å™¨ï¼ˆå…³é”®ç‚¹ç½®é¡¶ï¼‰
    st.markdown("**ğŸ¯ èŠ‚ç‚¹å¿«é€Ÿé€‰æ‹©**")
    
    # å®šä¹‰å…³é”®ç›‘æµ‹ç‚¹ï¼ˆä¼˜å…ˆæ˜¾ç¤ºï¼‰
    key_node_ids = [369, 385, 416, 91, 27, 140, 93, 201, 274, 148]  # é‡è¦èŠ‚ç‚¹ID
    
    # åˆ›å»ºé€‰é¡¹åˆ—è¡¨ï¼ˆå…³é”®ç‚¹ç½®é¡¶ï¼‰
    priority_options = []
    for nid in key_node_ids:
        if nid in all_nodes:
            x, y = all_nodes[nid]
            # æ·»åŠ æ ‡è®°ä¾¿äºè¯†åˆ«
            priority_options.append(f"â­ Node {nid} (X:{x:.1f}, Y:{y:.1f}) - å…³é”®ç‚¹")
    
    # å…¶ä½™èŠ‚ç‚¹
    other_options = [f"Node {nid} (X:{x:.1f}, Y:{y:.1f})" 
                     for nid, (x, y) in all_nodes.items() 
                     if nid not in key_node_ids]
    
    # åˆå¹¶é€‰é¡¹ï¼šæ‰‹åŠ¨è¾“å…¥ + å…³é”®ç‚¹ + å…¶ä»–èŠ‚ç‚¹
    node_options = ["æ‰‹åŠ¨è¾“å…¥"] + priority_options + other_options
    
    # ä½¿ç”¨ session_state è·Ÿè¸ªé€‰æ‹©
    if 'selected_node_index' not in st.session_state:
        st.session_state.selected_node_index = 0
    
    selected_option = st.selectbox(
        "é€‰æ‹©èŠ‚ç‚¹æˆ–æ‰‹åŠ¨è¾“å…¥åæ ‡",
        options=node_options,
        index=st.session_state.selected_node_index,
        help=f"ğŸ” å‰{len(priority_options)}ä¸ªä¸ºé‡ç‚¹ç›‘æµ‹ç‚¹ | å…±{len(all_nodes)}ä¸ªèŠ‚ç‚¹ | æ”¯æŒæœç´¢",
        key="node_selector"
    )
    
    # è§£æé€‰æ‹©å¹¶è®¾ç½®é»˜è®¤å€¼
    if selected_option == "æ‰‹åŠ¨è¾“å…¥":
        default_x, default_y = 200.0, 50.0
    else:
        # ä»é€‰é¡¹ä¸­æå– node_idï¼ˆå…¼å®¹å¸¦æ˜Ÿæ ‡å’Œä¸å¸¦æ˜Ÿæ ‡çš„æ ¼å¼ï¼‰
        parts = selected_option.split()
        node_id = int(parts[1] if parts[0] == "â­" else parts[1])
        default_x, default_y = all_nodes[node_id]
    
    # A. äº¤äº’è¾“å…¥åŒº
    c1, c2, c3, c4 = st.columns([1, 1, 1, 1])
    with c1:
        input_x = st.number_input("X åæ ‡ (m)", value=default_x, step=1.0)
    with c2:
        input_y = st.number_input("Y åæ ‡ (m)", value=default_y, step=1.0)
    with c3:
        input_t = st.number_input("æœªæ¥æ—¶é—´æ­¥ (Days)", value=current_time + 30, step=30)
    with c4:
        st.write("") # Spacer
        btn_predict = st.button("ğŸš€ å¯åŠ¨å¤šæ¨¡æ€è¿ç®—", use_container_width=True)
    
    # æ¨¡å¼åˆ‡æ¢å¼€å…³
    use_realtime = st.checkbox(
        "ğŸ”¬ å®æ—¶æ¨¡å‹æ¨ç†ï¼ˆè·³è¿‡æ•°æ®åº“ç¼“å­˜ï¼‰", 
        value=False,
        help="å‹¾é€‰åå°†è·³è¿‡é¢„è®¡ç®—æ•°æ®åº“ï¼Œç›´æ¥è¿è¡Œ AI æ¨¡å‹è¿›è¡Œå®æ—¶è®¡ç®—ï¼Œé€Ÿåº¦è¾ƒæ…¢ä½†å¯éªŒè¯æ¨¡å‹çœŸå®æ€§"
    )

    
    # B. è¿ç®—æ ¸å¿ƒé€»è¾‘
    # B. è¿ç®—æ ¸å¿ƒé€»è¾‘
    if btn_predict:
        # === 1. åŠ¨æ€è¿›åº¦æ¡ä½“éªŒ (Dynamic Progress Bar) ===
        progress_bar = st.progress(0, text="å¯åŠ¨æ··åˆä¸“å®¶ç³»ç»Ÿ...")
        import time
        
        # Phase 1: åŠ è½½æ¨¡å‹
        for i in range(30):
            time.sleep(0.01)
            progress_bar.progress(i, text="ğŸ“¡ æ­£åœ¨åŠ è½½ Stacking é›†æˆæ¨¡å‹æƒé‡...")
        
        # Phase 2: ç‰¹å¾å·¥ç¨‹
        for i in range(30, 60):
            time.sleep(0.01)
            progress_bar.progress(i, text="ğŸŒŠ æå– HST æ°´å‹-æ¸©åº¦ç‰¹å¾å› å­...")
            
        # Phase 3: BiLSTM æ¨ç†
        for i in range(60, 85):
            time.sleep(0.02) # ç¨æ…¢ä¸€ç‚¹æ¨¡æ‹Ÿæ·±åº¦å­¦ä¹ è®¡ç®—
            progress_bar.progress(i, text="ğŸ§  BiLSTMç¥ç»ç½‘ç»œæ­£åœ¨è¿›è¡Œæ—¶åºæ¨æ¼”...")
            
        # === æ•°æ®åº“æŸ¥è¯¢æ¨¡å¼ (Database Query Mode) ===
        db_success = False
        if not use_realtime:
            try:
                import sqlite3
                import json
                db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data", "processed", "predictions.db")
                
                if os.path.exists(db_path):
                    conn = sqlite3.connect(db_path)
                    cursor = conn.cursor()
                    
                    # æŸ¥è¯¢æœ€æ¥è¿‘çš„è®°å½•ï¼ˆå®¹é”™èŒƒå›´ï¼šåæ ‡ Â±5mï¼Œæ—¶é—´ Â±10å¤©ï¼‰
                    query = """
                        SELECT pred_settlement_stacking, pred_settlement_lstm, final_pred_settlement,
                               pred_settlement_std, pred_settlement_lower, pred_settlement_upper,
                               pred_horizontal_stacking, pred_horizontal_lstm, final_pred_horizontal,
                               pred_horizontal_std, pred_horizontal_lower, pred_horizontal_upper,
                               attention_weights, validated
                        FROM predictions
                        WHERE ABS(x - ?) < 5 
                          AND ABS(y - ?) < 5 
                          AND ABS(time_step - ?) < 10
                        ORDER BY (ABS(x - ?) + ABS(y - ?) + ABS(time_step - ?))
                        LIMIT 1
                    """
                    result = cursor.execute(query, (input_x, input_y, input_t, 
                                                   input_x, input_y, input_t)).fetchone()
                    conn.close()
                    
                    if result:
                        # æ‰¾åˆ°äº†æ•°æ®åº“è®°å½•ï¼ˆåŒç›®æ ‡ï¼‰
                        (pred_stacking, pred_lstm, final_pred, pred_std, pred_lower, pred_upper,
                         pred_horiz_stack, pred_horiz_lstm, final_pred_horiz, 
                         pred_horiz_std, pred_horiz_lower, pred_horiz_upper,
                         att_str, validated) = result
                        att_weights = np.array(json.loads(att_str))
                        db_success = True
                        st.success(f"âœ… å·²ä»é¢„æµ‹æ•°æ®åº“æ£€ç´¢ï¼ˆ{'æ·±åº¦éªŒè¯' if validated else 'æ ‡å‡†é¢„æµ‹'}ï¼‰")
            except Exception as db_error:
                st.info(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œåˆ‡æ¢è‡³å®æ—¶è®¡ç®—: {db_error}")
        
        # === çœŸå®æ¨¡å‹æ¨ç† (Real Model Inference) ===
        if not db_success or use_realtime:
            if use_realtime:
                st.info("ğŸ”¬ å®æ—¶ AI æ¨¡å‹æ¨ç†æ¨¡å¼ï¼ˆç»•è¿‡æ•°æ®åº“ï¼‰")

            import pickle
            import torch
            import torch.nn as nn
            
            # å®šä¹‰ BiLSTM æ¨¡å‹ç»“æ„ (éœ€è¦å’Œè®­ç»ƒæ—¶ä¸€è‡´)
            class Attention(nn.Module):
                def __init__(self, hidden_dim):
                    super(Attention, self).__init__()
                    self.W = nn.Linear(hidden_dim, hidden_dim)
                    self.u = nn.Linear(hidden_dim, 1, bias=False)
                def forward(self, x):
                    u = torch.tanh(self.W(x))
                    att_weights = torch.softmax(self.u(u), dim=1)
                    context = torch.sum(att_weights * x, dim=1)
                    return context, att_weights
            
            class AttentionBiLSTM(nn.Module):
                def __init__(self, input_dim, hidden_dim=64):
                    super(AttentionBiLSTM, self).__init__()
                    self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)
                    self.attention = Attention(hidden_dim * 2)
                    self.fc1 = nn.Linear(hidden_dim * 2, 64)
                    self.dropout = nn.Dropout(0.2)
                    self.fc2 = nn.Linear(64, 1)
                def forward(self, x):
                    lstm_out, _ = self.lstm(x)
                    context, att_weights = self.attention(lstm_out)
                    out = torch.relu(self.fc1(context))
                    out = self.dropout(out)
                    out = self.fc2(out)
                    return out, att_weights
            
            # åŠ è½½æ¨¡å‹
            models_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "models")
            
            try:
                # åŠ è½½ Stacking æ¨¡å‹
                with open(os.path.join(models_dir, "stacking_model.pkl"), 'rb') as f:
                    stack_data = pickle.load(f)
                stack_model = stack_data['model']
                scaler_X = stack_data['scaler_X']
                scaler_y = stack_data['scaler_y']
                feature_cols = stack_data['features']
                
                # åŠ è½½ BiLSTM æ¨¡å‹
                bilstm_checkpoint = torch.load(os.path.join(models_dir, "bilstm_model.pth"), map_location='cpu')
                bilstm_model = AttentionBiLSTM(bilstm_checkpoint['input_dim'])
                bilstm_model.load_state_dict(bilstm_checkpoint['model_state_dict'])
                bilstm_model.eval()
                
                # æ„å»ºè¾“å…¥ç‰¹å¾ (X, Y, Time, ä»¥åŠä¸€äº›é»˜è®¤çš„ Lag å€¼)
                # ç”±äºç”¨æˆ·åªè¾“å…¥ X, Y, Timeï¼Œæˆ‘ä»¬éœ€è¦ä»æ•°æ®ä¸­æŸ¥æ‰¾æœ€æ¥è¿‘çš„å†å²å€¼
                # æˆ–è€…ä½¿ç”¨åˆç†çš„é»˜è®¤å€¼
                
                # æŸ¥æ‰¾æ•°æ®ä¸­æœ€æ¥è¿‘çš„èŠ‚ç‚¹
                if df is not None:
                    # æ‰¾åˆ°åæ ‡æœ€æ¥è¿‘çš„èŠ‚ç‚¹
                    dist = np.sqrt((df['X'] - input_x)**2 + (df['Y'] - input_y)**2)
                    closest_idx = dist.idxmin()
                    closest_node_id = df.loc[closest_idx, 'Node_ID']
                    
                    # è·å–è¯¥èŠ‚ç‚¹çš„å†å²æ•°æ®
                    node_history = df[df['Node_ID'] == closest_node_id].sort_values('Time_Step')
                    
                    if not node_history.empty:
                        latest_row = node_history.iloc[-1]
                        lag_1 = latest_row['Total_Settlement']
                        lag_2 = node_history.iloc[-2]['Total_Settlement'] if len(node_history) > 1 else lag_1
                        lag_3 = node_history.iloc[-3]['Total_Settlement'] if len(node_history) > 2 else lag_2
                        lag_5 = node_history.iloc[-5]['Total_Settlement'] if len(node_history) > 4 else lag_3
                        rolling_mean = node_history['Total_Settlement'].tail(5).mean()
                    else:
                        lag_1, lag_2, lag_3, lag_5, rolling_mean = 0, 0, 0, 0, 0
                else:
                    lag_1, lag_2, lag_3, lag_5, rolling_mean = 0, 0, 0, 0, 0
                
                # æ„å»ºç‰¹å¾å‘é‡ (å’Œè®­ç»ƒæ—¶ä¸€è‡´)
                input_features = np.array([[input_x, input_y, input_t, lag_1, lag_2, lag_3, lag_5, rolling_mean]])
                input_scaled = scaler_X.transform(input_features)
                
                # Stacking é¢„æµ‹
                pred_stack_scaled = stack_model.predict(input_scaled)
                pred_stacking = scaler_y.inverse_transform(pred_stack_scaled.reshape(-1, 1)).flatten()[0] * 1000  # è½¬æ¢ä¸º mm
                
                # BiLSTM é¢„æµ‹ (éœ€è¦åºåˆ—è¾“å…¥ï¼Œè¿™é‡Œç”¨é‡å¤çš„å•æ­¥ä½œä¸ºç®€åŒ–)
                window_size = bilstm_checkpoint['window_size']
                seq_input = np.tile(input_scaled, (window_size, 1))  # ç®€åŒ–ï¼šé‡å¤è¾“å…¥ä½œä¸ºåºåˆ—
                seq_tensor = torch.FloatTensor(seq_input).unsqueeze(0)  # (1, window, features)
                
                with torch.no_grad():
                    pred_lstm_scaled, att_weights_tensor = bilstm_model(seq_tensor)
                pred_lstm = scaler_y.inverse_transform(pred_lstm_scaled.numpy().reshape(-1, 1)).flatten()[0] * 1000  # mm
                att_weights = att_weights_tensor.squeeze().numpy()
                
                # èåˆé¢„æµ‹
                final_pred = 0.6 * pred_stacking + 0.4 * pred_lstm
                
                # æ·»åŠ åŒç›®æ ‡å˜é‡å®šä¹‰ï¼ˆå®æ—¶æ¨¡å¼ç®€åŒ–ï¼šåªé¢„æµ‹æ²‰é™ï¼‰
                pred_std = abs(pred_stacking - pred_lstm) / 2
                pred_lower = final_pred - 2 * pred_std
                pred_upper = final_pred + 2 * pred_std
                
                # æ°´å¹³ä½ç§»ï¼ˆå®æ—¶æ¨¡å¼æš‚ä¸æ”¯æŒï¼Œä½¿ç”¨å ä½ç¬¦ï¼‰
                pred_horiz_stack = 0.0
                pred_horiz_lstm = 0.0
                final_pred_horiz = 0.0
                pred_horiz_std = 0.0
                pred_horiz_lower = 0.0
                pred_horiz_upper = 0.0
                
            except Exception as model_error:
                # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°æ—§çš„éšæœºæ•°é€»è¾‘
                st.warning(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨æ¼”ç¤ºæ¨¡å¼: {model_error}")
                pred_stacking = np.random.normal(5.2, 0.5)
                pred_lstm = np.random.normal(5.8, 0.8)
                final_pred = 0.6 * pred_stacking + 0.4 * pred_lstm
                att_weights = np.random.dirichlet(np.ones(5), size=1)[0]
                
                # æ·»åŠ åŒç›®æ ‡å˜é‡
                pred_std = 0.5
                pred_lower = final_pred - 1.0
                pred_upper = final_pred + 1.0
                pred_horiz_stack = 0.0
                pred_horiz_lstm = 0.0
                final_pred_horiz = 0.0
                pred_horiz_std = 0.0
                pred_horiz_lower = 0.0
                pred_horiz_upper = 0.0

        
        # Phase 4: ç”ŸæˆæŠ¥å‘Š
        progress_bar.progress(90, text="ğŸ“ AI ä¸“å®¶æ­£åœ¨æ’°å†™åˆ†ææŠ¥å‘Š...")
        
        # 5. LLM æ™ºèƒ½åˆ†æ (SiliconFlow API)
        try:
            from openai import OpenAI
            client = OpenAI(
                api_key="sk-jejoijaihwvytbvsubnerzvozdvlofcrzzcpwytlbeethcwv", # In prod, use st.secrets
                base_url="https://api.siliconflow.cn/v1"
            )
            
            # è®¡ç®—æ¨¡å‹å·®å¼‚åº¦ (ç”¨äºåˆ†æä¸€è‡´æ€§)
            model_diff_s = abs(pred_stacking - pred_lstm)
            model_diff_h = abs(pred_horiz_stack - pred_horiz_lstm)
            consistency_s = "é«˜" if model_diff_s < 1.0 else "ä¸­" if model_diff_s < 2.0 else "ä½"
            consistency_h = "é«˜" if model_diff_h < 1.0 else "ä¸­" if model_diff_h < 2.0 else "ä½"
            
            prompt = (
                f"ä½ æ˜¯ä¸€ä½å¤§åå®‰å…¨ç›‘æµ‹é¢†åŸŸçš„èµ„æ·±æ€»å·¥ç¨‹å¸ˆã€‚æ ¹æ®ä»¥ä¸‹åŒç›®æ ‡é¢„æµ‹æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½å·¥ç¨‹ç ”åˆ¤æŠ¥å‘Šï¼š\n"
                f"- æµ‹ç‚¹åæ ‡: ({input_x}, {input_y}) \n"
                f"- é¢„æµ‹æ—¶é—´: T+{input_t}å¤©\n\n"
                f"**ã€æ²‰é™é¢„æµ‹ã€‘**\n"
                f"- æœ€ç»ˆé›†æˆé¢„æµ‹: {final_pred:.2f} mm\n"
                f"- åˆ†æ¨¡å‹æ•°æ®: Stacking={pred_stacking:.2f}mm, BiLSTM={pred_lstm:.2f}mm (ä¸€è‡´æ€§={consistency_s})\n\n"
                f"**ã€æ°´å¹³ä½ç§»é¢„æµ‹ã€‘**\n"
                f"- æœ€ç»ˆé›†æˆé¢„æµ‹: {final_pred_horiz:.2f} mm\n"
                f"- åˆ†æ¨¡å‹æ•°æ®: Stacking={pred_horiz_stack:.2f}mm, BiLSTM={pred_horiz_lstm:.2f}mm (ä¸€è‡´æ€§={consistency_h})\n\n"
                f"æŠ¥å‘Šæ’°å†™è¦æ±‚ï¼ˆç²¾ç‚¼HTMLé£æ ¼ï¼‰ï¼š\n"
                f"1. **åŒç›®æ ‡ä¼šè¯Š**: åˆ†ææ²‰é™å’Œæ°´å¹³ä½ç§»çš„å…³è”æ€§ã€‚ä¾‹å¦‚ï¼Œæ²‰é™å¢å¤§æ—¶æ°´å¹³ä½ç§»æ˜¯å¦åŒæ­¥ï¼Ÿ\n"
                f"2. **æˆå› åˆ†æ**: ç»“åˆä¸¤ä¸ªæŒ‡æ ‡è§£é‡Šåä½“çŠ¶æ€ã€‚\n"
                f"3. **è¿ç»´å»ºè®®**: ç»™å‡ºå…·ä½“è¡ŒåŠ¨æŒ‡å—ã€‚\n"
                f"4. è¯­æ°”ä¸“ä¸šã€å®¢è§‚ã€‚ä¸è¦ç”¨ markdown æ ‡é¢˜ï¼Œç›´æ¥åˆ†æ®µè¾“å‡ºæ­£æ–‡ã€‚"
            )
            
            response = client.chat.completions.create(
                model="Qwen/Qwen2.5-7B-Instruct",  # æ›´å¿«çš„æ¨¡å‹
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å¤§åå®‰å…¨ç›‘æµ‹ä¸“å®¶ã€‚ç”¨100å­—ä»¥å†…ç®€æ´åˆ†æã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=200,  # é™åˆ¶é•¿åº¦æé«˜é€Ÿåº¦
                stream=False
            )
            llm_analysis = response.choices[0].message.content
        except Exception as e:
            llm_analysis = (
                f"âš ï¸ **æ™ºèƒ½åˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨**<br>"
                f"é”™è¯¯ä¿¡æ¯: {str(e)}<br>"
                f"**ç¦»çº¿åˆ†æ**: é¢„æµ‹æ²‰é™ {final_pred:.2f} mmï¼Œå»ºè®®å…³æ³¨å±€éƒ¨å˜å½¢è¶‹åŠ¿ã€‚"
            )
        
        # å®Œæˆ
        progress_bar.progress(100, text="âœ… åˆ†æå®Œæˆï¼")
        time.sleep(0.5)
        progress_bar.empty() # å¯é€‰ï¼šå®Œæˆåéšè—è¿›åº¦æ¡
        
        # å­˜å…¥ Session State ä¾›æŠ¥å‘Šç”Ÿæˆä½¿ç”¨
        st.session_state['latest_pred'] = final_pred
        st.session_state['latest_analysis'] = llm_analysis
        st.session_state['latest_node'] = f"{int(max_node)}" if 'max_node' in locals() else "N/A"
    
        # C. ç»“æœå±•ç¤ºåŒºï¼ˆåŒç›®æ ‡åŒåˆ—å¸ƒå±€ï¼‰
        st.markdown("### ğŸ¯ åŒç›®æ ‡é¢„æµ‹ç»“æœ")
        
        # ä½¿ç”¨2åˆ—å¸ƒå±€å±•ç¤ºåŒç›®æ ‡
        pred_col1, pred_col2 = st.columns(2)
        
        with pred_col1:
            st.markdown("#### ğŸ“‰ ç´¯è®¡æ²‰é™ (Settlement)")
            st.metric("æœ€ç»ˆé¢„æµ‹", f"{final_pred:.2f} mm", 
                     delta=f"Stacking: {pred_stacking:.2f}mm",
                     delta_color="inverse")
            st.metric("BiLSTM é¢„æµ‹", f"{pred_lstm:.2f} mm", 
                     delta=f"ç½®ä¿¡åŒºé—´: [{pred_lower:.1f}, {pred_upper:.1f}]")
            st.progress(0.95, text="æ¨¡å‹ç½®ä¿¡åº¦: 95%")
            
        with pred_col2:
            st.markdown("#### â†”ï¸ é¡ºæ²³å‘ä½ç§» (Horizontal)")
            st.metric("æœ€ç»ˆé¢„æµ‹", f"{final_pred_horiz:.2f} mm", 
                     delta=f"Stacking: {pred_horiz_stack:.2f}mm")
            st.metric("BiLSTM é¢„æµ‹", f"{pred_horiz_lstm:.2f} mm", 
                     delta=f"ç½®ä¿¡åŒºé—´: [{pred_horiz_lower:.1f}, {pred_horiz_upper:.1f}]")
            st.progress(0.92, text="æ¨¡å‹ç½®ä¿¡åº¦: 92%")
        
        # ä¸‹é¢ä¿ç•™åŸæœ‰çš„ XAI å’Œåˆ†ææŠ¥å‘Šå±•ç¤º
        res_c2, res_c3 = st.columns([1, 1])
            
        with res_c2:
            st.markdown("#### ğŸ§  XAI å¯è§£é‡Šæ€§")
            # ç»˜åˆ¶ Attention Bar Chart
            fig_att = go.Figure(go.Bar(
                x=[f"t-{i}" for i in range(10, 0, -1)],
                y=att_weights,
                marker_color=att_weights,
                marker_colorscale='Viridis'
            ))
            fig_att.update_layout(
                title="Time-Attention Weights",
                xaxis_title="å†å²çª—å£ (è¿‡å»10å¤©)",
                yaxis_title="å½±å“æƒé‡",
                height=300,
                margin=dict(l=0, r=0, t=30, b=0),
                paper_bgcolor='rgba(0,0,0,0)',
                plot_bgcolor='rgba(0,0,0,0)',
                font=dict(color='#E0E0E0')
            )
            st.plotly_chart(fig_att, use_container_width=True)
            
        with res_c3:
            st.markdown("#### ğŸ¤– AI ä¸“å®¶åˆ†ææŠ¥å‘Š")
            # === 2. ç¾åŒ–æŠ¥å‘Š UI (Styled Report Card) ===
            # Fix: Calculate formatted string outside f-string to avoid backslash error
            formatted_analysis = llm_analysis.replace('\n', '<br>')
            
            # åŠ¨æ€ç”Ÿæˆæ¨¡å‹å¯¹æ¯”æ¡ (HTML/CSS)
            # æ”¾å¤§å·®å¼‚ä»¥ä¾¿æ˜¾ç¤ºï¼Œä½†é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
            diff_width = min(100, abs(pred_stacking - pred_lstm) / (final_pred + 1e-6) * 100 * 5) 
            
            report_html = f"""
<div style="background-color: #1E2530; border-left: 5px solid #00ADB5; padding: 20px; border-radius: 5px; box-shadow: 0 4px 6px rgba(0,0,0,0.3); font-family: 'Segoe UI', sans-serif; color: #E0E0E0;">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span style="font-size: 20px; margin-right: 10px;">ğŸ©º</span>
<h4 style="margin: 0; color: #00ADB5;">æ¨¡å‹ä¼šè¯Š (Multi-Model Consensus)</h4>
</div>
<!-- New: Visual Model Comparison -->
<div style="background: #2D333B; padding: 8px; border-radius: 4px; margin-bottom: 15px; font-size: 12px;">
<div style="display: flex; justify-content: space-between; margin-bottom: 4px;">
<span>ğŸ“š Stacking: <b>{pred_stacking:.2f}</b></span>
<span>ğŸ§  BiLSTM: <b>{pred_lstm:.2f}</b></span>
</div>
<div style="height: 6px; background: #444; border-radius: 3px; position: relative;">
<div style="position: absolute; left: 0; top: 0; height: 100%; width: 50%; background: #00ADB5; opacity: 0.6; border-radius: 3px 0 0 3px;"></div>
<div style="position: absolute; right: 0; top: 0; height: 100%; width: 50%; background: #A020F0; opacity: 0.6; border-radius: 0 3px 3px 0;"></div>
<div style="position: absolute; left: 50%; top: -2px; height: 10px; width: 2px; background: #FFF;"></div>
<!-- å·®å¼‚æŒ‡ç¤ºå™¨ -->
<div style="position: absolute; top: 0; height: 100%; left: {50 - diff_width/2}%; width: {diff_width}%; background: rgba(255, 255, 0, 0.4);"></div>
</div>
<div style="text-align: center; color: #888; margin-top: 2px;">Stacking (Left) vs LSTM (Right)</div>
</div>
<div style="font-size: 13px; line-height: 1.6; opacity: 0.9;">
{formatted_analysis}
</div>
</div>
"""
            st.markdown(report_html, unsafe_allow_html=True)

# --- é‡ç‚¹éƒ¨ä½å…¨ç”Ÿå‘½å‘¨æœŸè¿½è¸ª (Key Node Tracker) ---
st.markdown("---")
st.header("ğŸ“ˆ é‡ç‚¹éƒ¨ä½å…¨ç”Ÿå‘½å‘¨æœŸè¿½è¸ª (Lifecycle Tracker)")

if df is not None:
    # ä»»åŠ¡ä¹¦æŒ‡å®šèŠ‚ç‚¹
    # è·å–æ‰€æœ‰èŠ‚ç‚¹åˆ—è¡¨ (ç”¨äºæœç´¢)
    all_nodes_sorted = sorted(df['Node_ID'].unique())
    
    # é»˜è®¤æ¨èèŠ‚ç‚¹ (Key Nodes)
    default_nodes = [369, 385, 416, 91, 27]
    
    # æ„é€ ä¼˜å…ˆçº§åˆ—è¡¨: æ¨èèŠ‚ç‚¹ç½®é¡¶ + å…¶ä½™èŠ‚ç‚¹æŒ‰åºæ’åˆ—
    # ç¡®ä¿é»˜è®¤èŠ‚ç‚¹åœ¨æ•°æ®ä¸­å­˜åœ¨
    priority_nodes = [n for n in default_nodes if n in all_nodes_sorted]
    other_nodes = [n for n in all_nodes_sorted if n not in priority_nodes]
    
    # åˆå¹¶é€‰é¡¹åˆ—è¡¨ (æ¨èçš„æ’å‰é¢)
    options_list = priority_nodes + other_nodes
    
    # äº¤äº’å¼é€‰æ‹©å™¨ (Interactive Selector)
    selected_nodes = st.multiselect(
        "ğŸ¯ é€‰æ‹©ç›‘æµ‹ç‚¹ä½ (Select Nodes to Track)",
        options=options_list,
        default=priority_nodes,
        help="æ¨èé‡ç‚¹éƒ¨ä½å·²ç½®é¡¶æ˜¾ç¤ºã€‚æ‚¨å¯åœ¨ä¸‹æ‹‰æ¡†ä¸­æœç´¢å¹¶æ·»åŠ ä»»æ„èŠ‚ç‚¹ã€‚",
        format_func=lambda x: f"Node {int(x)}" if x == int(x) else f"Node {x}"
    )
    
    if selected_nodes:
        tracker_df = df[df['Node_ID'].isin(selected_nodes)].copy()
        
        # ç»˜åˆ¶å¤šçº¿å›¾
        fig_track = px.line(
            tracker_df, 
            x="Time_Step", 
            y="Total_Settlement", 
            color="Node_ID",
            title="å…³é”®èŠ‚ç‚¹ç´¯è®¡æ²‰é™è¿‡ç¨‹çº¿ (Cumulative Settlement Process)",
            labels={"Time_Step": "Time (Days)", "Total_Settlement": "Settlement (m)", "Node_ID": "Node"},
            markers=False # æ•°æ®ç‚¹å¯†é›†æ—¶å…³é—­æ ‡è®°æ›´æ¸…æ™°ä»¥å±•ç¤ºè¶‹åŠ¿
        )
        
        # æ·»åŠ äº¤äº’è”åŠ¨çº¢çº¿ (Current Time Indicator)
        fig_track.add_vline(x=current_time, line_width=2, line_dash="dash", line_color="red", annotation_text="Current Time")
        
        fig_track.update_layout(
            height=450,
            hovermode="x unified",
            xaxis=dict(showgrid=False),
            yaxis=dict(showgrid=True, gridcolor='#333'),
            # å°†èƒŒæ™¯è‰²æ”¹ä¸ºå®åº•æ·±è‰²ï¼Œé¿å…ä¸‹è½½æ—¶å‡ºç°é€æ˜é©¬èµ›å…‹
            paper_bgcolor='#1E2530', 
            plot_bgcolor='#1E2530',
            font=dict(color='#E0E0E0'),
            legend=dict(orientation="h", y=1.1, x=0)
        )
        
        # é…ç½®ä¸‹è½½æŒ‰é’®åŠŸèƒ½ (Enable High-Res Download with Background)
        config = {
            'displayModeBar': True,
            'displaylogo': False,
            'toImageButtonOptions': {
                'format': 'png', 
                'filename': f'Dam_Lifecycle_Tracker_{datetime.now().strftime("%Y%m%d")}_T{current_time}',
                'height': 900,
                'width': 1600,
                'scale': 2 # High resolution download
            },
            'modeBarButtonsToRemove': ['lasso2d', 'select2d']
        }
        
        st.plotly_chart(fig_track, use_container_width=True, config=config)
        st.caption(f"ğŸ’¡ æç¤ºï¼šç‚¹å‡»å›¾è¡¨å³ä¸Šè§’çš„ç…§ç›¸æœºå›¾æ ‡ ğŸ“· å³å¯ä¸‹è½½é«˜æ¸…æ›²çº¿å›¾ã€‚å½“å‰å·²é€‰ä¸­ {len(selected_nodes)} ä¸ªå…³é”®èŠ‚ç‚¹ã€‚")
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨ä¸Šæ–¹ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹©è‡³å°‘ä¸€ä¸ªèŠ‚ç‚¹è¿›è¡Œè¿½è¸ªã€‚")

# --- è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆå™¨ (Sidebar Bottom) ---
with st.sidebar:
    st.markdown("---")
    st.markdown("### ğŸ“‘ æŠ¥å‘Šç”Ÿæˆ")
    
    # å‡†å¤‡æŠ¥å‘Šæ•°æ®
    # å¦‚æœè¿˜æ²¡æœ‰ç‚¹å‡»è¿‡ AI é¢„æµ‹ï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼
    rpt_pred = st.session_state.get('latest_pred', 0.0)
    rpt_analysis = st.session_state.get('latest_analysis', "ï¼ˆæš‚æ—  AI åˆ†æï¼Œè¯·å…ˆè¿è¡Œé¢„æµ‹æ¨¡å—ï¼‰")
    
    # è·å–ä¹‹å‰è®¡ç®—çš„ KPI (éœ€è¦è®¿é—®å±€éƒ¨å˜é‡ï¼Œå¦‚æœåœ¨ sidebar æœ€åè¿è¡Œ block å¯ä»¥è®¿é—®åˆ°ä¸Šæ–¹å®šä¹‰çš„å˜é‡å—ï¼Ÿ
    # åœ¨ Streamlit ä¸­ï¼Œå¦‚æœå˜é‡æ˜¯åœ¨ä¸»è„šæœ¬æµç¨‹ä¸­å®šä¹‰çš„ï¼Œåç»­ä»£ç å¯ä»¥è®¿é—®ã€‚
    # ä¸ºäº†ç¨³å¥ï¼Œä½¿ç”¨ .get æˆ–é»˜è®¤å€¼)
    rpt_max_settle = f"{max_settle_mm:.2f}" if 'max_settle_mm' in locals() else "N/A"
    rpt_max_node = f"{int(max_node)}" if 'max_node' in locals() else "N/A"
    rpt_rate = avg_rate_str if 'avg_rate_str' in locals() else "N/A"
    rpt_score = f"{health_score:.1f}" if 'health_score' in locals() else "N/A"
    
    report_text = f"""# æ²³æµ·å¤§å­¦åœŸçŸ³åæ•°å­—å­ªç”Ÿç›‘æµ‹å‘¨æŠ¥
**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ç›‘æµ‹æ—¶é—´æ­¥**: ç¬¬ {current_time} å¤©

## 1. æ ¸å¿ƒæŒ‡æ ‡æ‘˜è¦
- **æœ€å¤§æ²‰é™é‡**: {rpt_max_settle} mm (ä½äºèŠ‚ç‚¹ {rpt_max_node})
- **å¹³å‡å˜å½¢é€Ÿç‡**: {rpt_rate}
- **æ•´ä½“å¥åº·è¯„åˆ†**: {rpt_score} åˆ†

## 2. AI æ™ºèƒ½åˆ†æç»“è®º
- **æ··åˆæ¨¡å‹é¢„æµ‹å€¼**: {rpt_pred:.2f} mm
- **ä¸“å®¶å»ºè®®**:
{rpt_analysis}

---
*Based on æ²³æµ·å¤§å­¦Â·æ°´åˆ©å¤§æ•°æ®å’Œä¿¡æ¯æŒ–æ˜æŠ€æœ¯è¯¾ç¨‹è®¾è®¡ | Developer: ç« æ¶µç¡•*
"""
    
    st.download_button(
        label="ğŸ“„ ä¸‹è½½ç›‘æµ‹å‘¨æŠ¥ (Markdown)",
        data=report_text,
        file_name=f"Dam_Monitor_Report_T{current_time}.md",
        mime="text/markdown"
    )

# --- Footer ---
st.markdown("<br><br>", unsafe_allow_html=True)
st.markdown(
    """
    <div style='text-align: center; color: #666; font-size: 12px;'>
        ğŸ“ æ²³æµ·å¤§å­¦Â·æ°´åˆ©å¤§æ•°æ®å’Œä¿¡æ¯æŒ–æ˜æŠ€æœ¯è¯¾ç¨‹è®¾è®¡ | å¼€å‘è€…ï¼šç« æ¶µç¡• (æ™ºæ…§æ°´åˆ©ä¸“ä¸š)
    </div>
    """, 
    unsafe_allow_html=True
)
