import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
from scipy.interpolate import griddata
# å°è¯•å¯¼å…¥ Visualizerï¼Œå¦‚æœ src æœªåœ¨è·¯å¾„ä¸­åˆ™æ·»åŠ 
import sys
if "src" not in sys.path:
    sys.path.append(os.path.join(os.path.dirname(__file__), "src"))
try:
    from src.visualizer import Visualizer
except ImportError:
    # Fallback if running from src directory or other structure
    from visualizer import Visualizer

# 1. åŸºç¡€é…ç½®
st.set_page_config(
    layout="wide", 
    page_title="åœŸçŸ³åæ•°å­—å­ªç”Ÿå¹³å°",
    page_icon="ğŸŒŠ"
)

# 2. å¼ºåˆ¶æ·±è‰²æ¨¡å¼ & å·¥ä¸šé£ CSS
st.markdown("""
<style>
    /* å…¨å±€èƒŒæ™¯è®¾ä¸ºæ·±ç° */
    .stApp {
        background-color: #0E1117;
    }
    
    /* ä¾§è¾¹æ è®¾ä¸ºåŠé€æ˜é»‘ï¼Œå¢åŠ ç£¨ç ‚æ„Ÿ */
    [data-testid="stSidebar"] {
        background-color: rgba(20, 20, 30, 0.9);
        border-right: 1px solid #333;
    }
    
    /* å­—ä½“é¢œè‰²ä¼˜åŒ– */
    .stMarkdown, .stText, h1, h2, h3 {
        color: #E0E0E0 !important;
    }
    
    /* æ»‘å—æ ·å¼å¾®è°ƒ (å¯é€‰) */
    .stSlider > div > div > div > div {
        background-color: #00ADB5;
    }
    
    /* æŒ‡æ ‡å¡ç‰‡æ ·å¼ */
    div[data-testid="metric-container"] {
        background-color: #1E212B;
        padding: 15px;
        border-radius: 8px;
        border: 1px solid #333;
    }
</style>
""", unsafe_allow_html=True)

# æ•°æ®åŠ è½½å‡½æ•°
@st.cache_data
def load_data():
    # åŠ¨æ€è·å–è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_path = os.path.join(current_dir, "data", "processed", "master_dataset.csv")
    node_path = os.path.join(current_dir, "data", "raw", "Node.xlsx") # éœ€è¦èŠ‚ç‚¹åæ ‡ç”¨äº3Dæ’å€¼
    
    if not os.path.exists(data_path):
        st.error(f"æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {data_path}")
        return None, None
        
    df = pd.read_csv(data_path)
    
    # åŠ è½½èŠ‚ç‚¹åæ ‡ (Master Dataset å¯èƒ½æœ‰äº›æ—¶é—´æ­¥ç¼ºåæ ‡ï¼Œæˆ–è€…ä¸ºäº†3Dæ’å€¼æ–¹ä¾¿ç›´æ¥è¯»Nodeè¡¨)
    # å…¶å® master_dataset å·²ç»åŒ…å« X, Y åˆ—ï¼Œå¯ä»¥ç›´æ¥ç”¨
    # ä½†ä¸ºäº†æ„å»º Visualizerï¼Œæˆ‘ä»¬éœ€è¦ node_df
    # æˆ‘ä»¬å¯ä»¥ä» df ä¸­æå–å”¯ä¸€çš„ node_df
    node_df = df[['Node_ID', 'X', 'Y']].drop_duplicates()
    
    return df, node_df

# åŠ è½½æ•°æ®
df, node_df = load_data()
viz = Visualizer(node_df) if node_df is not None else None

# 3. ä¾§è¾¹æ  (Control Panel)
with st.sidebar:
    st.title("ğŸ›ï¸ ç›‘æµ‹æ§åˆ¶å°")
    st.markdown("---")
    
    # å…¨å±€æ—¶é—´è½´
    current_time = st.slider(
        "â±ï¸ æ—¶é—´å›æº¯ (Time Machine)", 
        min_value=30, 
        max_value=1500, 
        step=30,
        value=1500,
        help="æ‹–åŠ¨æ»‘å—å›æº¯å†å²å˜å½¢çŠ¶æ€"
    )
    
    st.markdown("### ğŸ”ï¸ åœºæ™¯å‚æ•° (HST æ¨¡å‹ä»¿çœŸ)")
    st.info("åŸºäº Hydrostatic-Seasonal-Time ç†è®º")
    st.latex(r"\delta = a_0 + a_1 H + a_2 H^2 + b_1 T + c_1 \theta")
    
    water_level = st.slider("ğŸŒŠ ä¸Šæ¸¸æ°´ä½ H (m)", 140.0, 180.0, 165.0, step=0.5)
    temperature = st.slider("ğŸŒ¡ï¸ ç¯å¢ƒæ¸©åº¦ T (Â°C)", -10.0, 40.0, 25.0, step=1.0)
    
    # --- HST æ­£å‘æ¨æ¼”é€»è¾‘ ---
    # å®šä¹‰åŸºå‡†å‚æ•° (Reference State)
    H0, T0 = 165.0, 25.0
    
    # HST è®¡ç®—å·²ç§»è‡³ä¸»æµç¨‹ä»¥ç¡®ä¿å…¨å±€ç”Ÿæ•ˆ
    
    # æ¨¡å¼åˆ‡æ¢ï¼šçœŸå®ç‰©ç†æ¨¡å¼ vs ç­”è¾©æ¼”ç¤ºæ¨¡å¼
    use_demo_mode = st.checkbox("ğŸ”¥ å¼€å¯çµæ•åº¦å¢å¼º (Demo Mode)", value=True, help="é€‰ä¸­ï¼šæ”¾å¤§ç‰©ç†ç³»æ•°ä»¥å±•ç¤ºè¶‹åŠ¿ï¼›å–æ¶ˆï¼šä½¿ç”¨çœŸå®å¾®å°å˜å½¢é‡")

    # --- HST æ­£å‘æ¨æ¼”é€»è¾‘ (æ”¾åˆ° Sidebar å†…éƒ¨ä»¥å®ç°å®æ—¶é¢„è§ˆï¼Œä¸”å˜é‡è‡ªåŠ¨å…¨å±€å¯è§) ---
    if use_demo_mode:
        k_H1, k_H2 = -0.5, -0.01 
        k_T = 0.5
    else:
        k_H1, k_H2 = -0.01, -0.0002
        k_T = 0.01

    # å®šä¹‰åŸºå‡†å‚æ•° (Reference State)
    H0, T0 = 165.0, 25.0
    
    # è®¡ç®— HST å¢é‡ (Delta in mm)
    delta_H = k_H1 * (water_level - H0) + k_H2 * (water_level - H0)**2
    delta_T = k_T * (temperature - T0)
    hst_total_delta = delta_H + delta_T

    st.markdown("---")
    st.caption(f"ä»¿çœŸé¢„è§ˆ: é¢„è®¡å½±å“ KPI")
    
    st.markdown("---")
    st.caption(f"HST ä»¿çœŸå¢é‡: **{hst_total_delta:+.2f} mm**")
    if abs(hst_total_delta) > 0.1:
        st.write(f"- æ°´å‹å› å­: {delta_H:+.2f} mm")
        st.write(f"- çƒ­èƒ€å› å­: {delta_T:+.2f} mm")
    
    st.markdown("---")
    st.markdown("---")
    st.info(f"å½“å‰ä»¿çœŸæ­¥: **{current_time}**")

# --- HST è®¡ç®—é€»è¾‘å·²ç§»å› Sidebar ---
# å˜é‡ hst_total_delta åœ¨æ­¤å¤„ä¾ç„¶å¯ç”¨ (Python ä½œç”¨åŸŸç‰¹æ€§)

# 4. ä¸»å¸ƒå±€å®¹å™¨
st.title("ğŸŒŠ åŸºäºæ•°å­—å­ªç”Ÿçš„åœŸçŸ³åå…¨ç”Ÿå‘½å‘¨æœŸæ™ºæ…§ç›‘æµ‹ç³»ç»Ÿ")
st.markdown("##### Digital Twin System for Earth-Rock Dam Lifecycle Monitoring")
st.caption("æ ¸å¿ƒç®—æ³•: Stacking Ensemble + BiLSTM | ä»¿çœŸå¼•æ“: HST Model (Ref: [WHU-Wzj/Dam-deformation-prediction](https://github.com/WHU-Wzj/Dam-deformation-prediction))")

# 3:1 åˆ†æ 
col_main, col_kpi = st.columns([3, 1])

with col_main:
    st.markdown("### ğŸ—ºï¸ æ ¸å¿ƒç›‘æµ‹è§†å›¾ (Core Monitor View)")
    
    if df is not None:
        tab1, tab2 = st.tabs(["2D ç­‰å€¼çº¿è§†å›¾", "3D å…¨æ¯åœ°å½¢è§†å›¾"])
        
        with tab1:
            st.caption("å®æ—¶å˜å½¢ç­‰å€¼çº¿ (Deformation Contour)")
            fig_2d = viz.plot_dam_contour(df, current_time, value_col='Total_Settlement')
            if fig_2d:
                st.plotly_chart(fig_2d, use_container_width=True, config={
                    'displayModeBar': True,
                    'toImageButtonOptions': {'format': 'png', 'scale': 2, 'filename': 'Dam_2D_Contour'}
                })
            else:
                st.warning(f"æ—¶é—´æ­¥ {current_time} æ— æ•°æ®")
                
        with tab2:
            st.caption("3D å…¨æ¯åœ°å½¢ (Holographic Terrain)")
            # 3D ç»˜å›¾é€»è¾‘
            step_df = df[df['Time_Step'] == current_time]
            if not step_df.empty:
                x = step_df['X'].values
                y = step_df['Y'].values
                # æ²‰é™é€šå¸¸æ˜¯è´Ÿå€¼ï¼Œä¸ºäº†3Dæ˜¾ç¤ºæ•ˆæœï¼Œæˆ‘ä»¬å¯ä»¥å–ç»å¯¹å€¼æˆ–è€…ç›´æ¥ç”¨
                # ä»»åŠ¡ä¹¦è¦æ±‚: Z è½´æ”¾å¤§ 100 å€
                z = step_df['Total_Settlement'].values
                
                # æ’å€¼ç½‘æ ¼
                grid_x, grid_y = np.mgrid[min(x):max(x):100j, min(y):max(y):100j]
                grid_z = griddata((x, y), z, (grid_x, grid_y), method='cubic')
                
                # 3D Surface Plot
                fig_3d = go.Figure(data=[go.Surface(
                    z=grid_z * 100, # Zè½´æ”¾å¤§100å€
                    x=grid_x, 
                    y=grid_y,
                    colorscale='Turbo',
                    lighting=dict(roughness=0.5, ambient=0.5, diffuse=0.5), # å…‰ç…§æ•ˆæœ
                    lightposition=dict(x=0, y=0, z=2000) # å…‰æºä½ç½®
                )])
                
                fig_3d.update_layout(
                    title=f'3D Terrain (x100) - T={current_time}',
                    scene=dict(
                        xaxis_title='X',
                        yaxis_title='Y',
                        zaxis_title='Settlement',
                        aspectratio=dict(x=1, y=1, z=0.5),
                        bgcolor='#0E1117' # 3D åœºæ™¯èƒŒæ™¯
                    ),
                    margin=dict(l=0, r=0, b=0, t=30),
                    height=500,
                    paper_bgcolor='#0E1117',
                    font=dict(color='#E0E0E0')
                )
                st.plotly_chart(fig_3d, use_container_width=True, config={
                    'displayModeBar': True,
                    'toImageButtonOptions': {'format': 'png', 'scale': 2, 'filename': 'Dam_3D_Terrain'}
                })
            else:
                st.warning("å½“å‰æ—¶é—´æ­¥æ— æ•°æ®ç”¨äº 3D å»ºæ¨¡")
    else:
        st.error("æ•°æ®åŠ è½½å¤±è´¥ã€‚")

with col_kpi:
    st.markdown(f"### ğŸ“Š å…³é”®æŒ‡æ ‡ (T={current_time})")
    
    # åŠ¨æ€è®¡ç®— KPI
    if df is not None:
        current_step_df = df[df['Time_Step'] == current_time]
        
        # å°è¯•è·å–ä¸Šä¸€æœˆæ•°æ®è®¡ç®—é€Ÿç‡ (Time Machine 30å¤©æ­¥é•¿)
        prev_time = current_time - 30
        prev_step_df = df[df['Time_Step'] == prev_time] if prev_time > 0 else pd.DataFrame()
        
        if not current_step_df.empty:
            # 1. æœ€å¤§æ²‰é™
            min_val = current_step_df['Total_Settlement'].min() # è´Ÿå€¼ï¼Œè¶Šå°æ²‰é™è¶Šå¤§
            max_settle_mm = min_val * 1000
            max_node = current_step_df.loc[current_step_df['Total_Settlement'].idxmin(), 'Node_ID']
            
            # 2. å¹³å‡å˜å½¢é€Ÿç‡ (mm/day)
            avg_rate_str = "--"
            avg_rate_delta = None
            if not prev_step_df.empty:
                # ç®€å•è®¡ç®—æ•´åå¹³å‡æ²‰é™å·®
                raw_curr_mean = current_step_df['Total_Settlement'].mean() * 1000
                prev_mean = prev_step_df['Total_Settlement'].mean() * 1000
                
                # åŸå§‹é€Ÿç‡ (Historical)
                raw_rate = (raw_curr_mean - prev_mean) / 30.0
                
                # å åŠ  HST æ•ˆåº”åçš„é€Ÿç‡ (Simulated)
                # å‡è®¾ HST å˜å½¢æ˜¯"çªå‘"çš„ï¼Œå°†å…¶è®¡å…¥å½“å‰çŠ¶æ€
                sim_curr_mean = raw_curr_mean + hst_total_delta
                
                # âš ï¸ å…³é”®ä¿®æ”¹: ä¸ºäº†è®©ç”¨æˆ·æ˜æ˜¾çœ‹åˆ°é€Ÿç‡å˜åŒ–ï¼Œæˆ‘ä»¬å°† HST å¢é‡è§†ä¸º"ç¬æ—¶å“åº”", 
                # ä½†ä¸ºäº†ç»´æŒå•ä½(mm/d)çš„ç‰©ç†æ„ä¹‰ï¼Œæˆ‘ä»¬å‡è®¾è¿™ä¸ªå¢é‡æ˜¯åœ¨æœ€å 1 å¤©å‘ç”Ÿçš„ï¼Œæˆ–è€…å¹³å‡åˆ†æ‘Šåˆ° 30 å¤©
                # è¿™é‡Œé‡‡ç”¨å¹³å‡åˆ†æ‘Šï¼Œä½†å› ä¸º hst_delta å¯èƒ½å¾ˆå¤§ï¼Œé™¤ä»¥ 30 åä¾ç„¶å¯è§
                sim_rate = (sim_curr_mean - prev_mean) / 30.0
                
                avg_rate_str = f"{sim_rate:.3f} mm/d"
                
                # å˜åŒ–ç‡æ˜¾ç¤º
                if abs(prev_mean) > 1e-6:
                     # å¯¹æ¯” "æœ‰ä»¿çœŸ vs æ— ä»¿çœŸ" çš„å˜åŒ–ï¼Œæˆ–è€… "å½“å‰ vs è¿‡å»"
                     # è¿™é‡Œæ˜¾ç¤ºç›¸å¯¹äº T-30 çš„å˜åŒ–ç™¾åˆ†æ¯”
                     rate_diff_pct = (sim_rate / abs(prev_mean)) * 100 
                     avg_rate_delta = f"{rate_diff_pct:.1f}%"
            
            # 3. å¥åº·åº¦è¯„åˆ† (åŸºäº HST ä¿®æ­£åçš„æ²‰é™)
            # åŸå§‹ç›‘æµ‹å€¼ + HST ä»¿çœŸå¢é‡ = æœ€ç»ˆæ¨æ¼”æ²‰é™
            final_settle_mm = max_settle_mm + hst_total_delta
            
            # å¥åº·åº¦è®¡ç®—
            health_score = max(0, 100 - abs(final_settle_mm) * 0.2)
            
            # çŠ¶æ€åˆ¤å®š
            if health_score > 85:
                status_icon, status_text = "ğŸŸ¢", "å¥åº· (Stable)"
            elif health_score > 60:
                status_icon, status_text = "ğŸŸ¡", "æ³¨æ„ (Warning)"
            else:
                status_icon, status_text = "ğŸ”´", "å±é™© (Critical)"
            
            # è®¡ç®—æ²‰é™å¢é‡ä½œä¸º Delta (ç›¸å¯¹äº T-30)
            pct_change = "0%"
            if not prev_step_df.empty:
                prev_min_mm = prev_step_df['Total_Settlement'].min() * 1000
                real_diff = abs(max_settle_mm) - abs(prev_min_mm)
                
                # æ˜¾å¼æ˜¾ç¤ºç»„æˆ
                if abs(hst_total_delta) > 0.01:
                    pct_change = f"ç›‘æµ‹ {real_diff:+.1f} | ä»¿çœŸ {hst_total_delta:+.1f}"
                else:
                    pct_change = f"ç›‘æµ‹å¢é‡ {real_diff:+.1f}"
            
            st.metric("ğŸš¨ æœ€å¤§æ²‰é™ç‚¹ (Node)", f"{int(max_node)}", f"{final_settle_mm:.2f} mm", delta_color="inverse", help=f"åŸå§‹è§‚æµ‹: {max_settle_mm:.2f} + HSTä»¿çœŸ: {hst_total_delta:.2f}")
            st.metric("ğŸ“‰ å¹³å‡å˜å½¢é€Ÿç‡ (Rate)", avg_rate_str, avg_rate_delta, help=f"å«ä»¿çœŸå¢é‡çš„ 30å¤©å¹³å‡é€Ÿç‡\n(HST Delta: {hst_total_delta:.2f} mm)")
            st.metric(f"ğŸ›¡ï¸ å¤§åå¥åº·åº¦ ({status_text})", f"{health_score:.1f} åˆ†", pct_change, delta_color="normal")
            
        else:
            st.info("ç­‰å¾…æ•°æ®...")
    
    st.markdown("---")
    st.markdown("#### ğŸš€ ç³»ç»ŸçŠ¶æ€")
    if abs(hst_total_delta) > 0.1:
        st.info(f"ğŸ§ª HST ä»¿çœŸç”Ÿæ•ˆä¸­\n\n- æ°´ä½/æ¸©åº¦å¯¼è‡´å˜å½¢: **{hst_total_delta:+.2f} mm**\n- å…³é”®æŒ‡æ ‡å·²å®æ—¶ä¿®æ­£")
    else:
        st.success("âœ… å¤„äºåŸºå‡†ç¯å¢ƒçŠ¶æ€ (æ— é¢å¤–ä»¿çœŸå¢é‡)")

    # --- ä¿®å¤æŠ¥å‘Šç”Ÿæˆå™¨å˜é‡å bug ---
    # (æ­¤æ®µé€»è¾‘å®é™…åœ¨ Sidebar åº•éƒ¨ï¼Œä½†ä¸ºäº†æ–¹ä¾¿é˜…è¯»é€»è¾‘ï¼Œæˆ‘ä»¬ç¡®è®¤å˜é‡åä¸€è‡´æ€§)
    # report_section_vars = {'max_settle_mm': final_settle_mm, ...}


# --- åº•éƒ¨: AI é¢„æµ‹å®éªŒå®¤ ---
st.markdown("---")
with st.expander("ğŸ¤– æ··åˆä¸“å®¶é¢„æµ‹ç³»ç»Ÿ (Hybrid Expert System)", expanded=True):
    st.markdown("##### The Lab: åŸºäº Stacking é›†æˆå­¦ä¹ ä¸ Attention-BiLSTM çš„å¤šæ¨¡æ€é¢„æµ‹")
    
    # ä»æ•°æ®åº“åŠ¨æ€åŠ è½½æ‰€æœ‰èŠ‚ç‚¹
    @st.cache_data
    def load_all_nodes():
        import sqlite3
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data", "processed", "predictions.db")
        if os.path.exists(db_path):
            conn = sqlite3.connect(db_path)
            nodes = conn.execute('SELECT DISTINCT node_id, x, y FROM predictions ORDER BY node_id').fetchall()
            conn.close()
            return {int(n[0]): (float(n[1]), float(n[2])) for n in nodes}
        return {}
    
    all_nodes = load_all_nodes()
    
    # èŠ‚ç‚¹é€‰æ‹©å™¨ï¼ˆå…³é”®ç‚¹ç½®é¡¶ï¼‰
    st.markdown("**ğŸ¯ èŠ‚ç‚¹å¿«é€Ÿé€‰æ‹©**")
    
    # å®šä¹‰å…³é”®ç›‘æµ‹ç‚¹ï¼ˆä¼˜å…ˆæ˜¾ç¤ºï¼‰
    key_node_ids = [369, 385, 416, 91, 27, 140, 93, 201, 274, 148]  # é‡è¦èŠ‚ç‚¹ID
    
    # åˆ›å»ºé€‰é¡¹åˆ—è¡¨ï¼ˆå…³é”®ç‚¹ç½®é¡¶ï¼‰
    priority_options = []
    for nid in key_node_ids:
        if nid in all_nodes:
            x, y = all_nodes[nid]
            # æ·»åŠ æ ‡è®°ä¾¿äºè¯†åˆ«
            priority_options.append(f"â­ Node {nid} (X:{x:.1f}, Y:{y:.1f}) - å…³é”®ç‚¹")
    
    # å…¶ä½™èŠ‚ç‚¹
    other_options = [f"Node {nid} (X:{x:.1f}, Y:{y:.1f})" 
                     for nid, (x, y) in all_nodes.items() 
                     if nid not in key_node_ids]
    
    # åˆå¹¶é€‰é¡¹ï¼šæ‰‹åŠ¨è¾“å…¥ + å…³é”®ç‚¹ + å…¶ä»–èŠ‚ç‚¹
    node_options = ["æ‰‹åŠ¨è¾“å…¥"] + priority_options + other_options
    
    # ä½¿ç”¨ session_state è·Ÿè¸ªé€‰æ‹©
    if 'selected_node_index' not in st.session_state:
        st.session_state.selected_node_index = 0
    
    selected_option = st.selectbox(
        "é€‰æ‹©èŠ‚ç‚¹æˆ–æ‰‹åŠ¨è¾“å…¥åæ ‡",
        options=node_options,
        index=st.session_state.selected_node_index,
        help=f"ğŸ” å‰{len(priority_options)}ä¸ªä¸ºé‡ç‚¹ç›‘æµ‹ç‚¹ | å…±{len(all_nodes)}ä¸ªèŠ‚ç‚¹ | æ”¯æŒæœç´¢",
        key="node_selector"
    )
    
    # è§£æé€‰æ‹©å¹¶è®¾ç½®é»˜è®¤å€¼
    if selected_option == "æ‰‹åŠ¨è¾“å…¥":
        default_x, default_y = 200.0, 50.0
    else:
        # ä»é€‰é¡¹ä¸­æå– node_idï¼ˆå…¼å®¹å¸¦æ˜Ÿæ ‡å’Œä¸å¸¦æ˜Ÿæ ‡çš„æ ¼å¼ï¼‰
        try:
            parts = selected_option.split()
            # æŸ¥æ‰¾ "Node" åé¢çš„æ•°å­—
            node_idx = parts.index("Node") + 1
            node_id = int(parts[node_idx])
            default_x, default_y = all_nodes[node_id]
        except (ValueError, IndexError, KeyError) as e:
            st.error(f"è§£æèŠ‚ç‚¹IDå¤±è´¥: {selected_option}ï¼Œé”™è¯¯: {e}")
            default_x, default_y = 200.0, 50.0
    
    # A. äº¤äº’è¾“å…¥åŒº
    c1, c2, c3, c4 = st.columns([1, 1, 1, 1])
    with c1:
        input_x = st.number_input("X åæ ‡ (m)", value=default_x, step=1.0)
    with c2:
        input_y = st.number_input("Y åæ ‡ (m)", value=default_y, step=1.0)
    with c3:
        input_t = st.number_input("æœªæ¥æ—¶é—´æ­¥ (Days)", value=current_time + 30, step=30)
    with c4:
        st.write("") # Spacer
        btn_predict = st.button("ğŸš€ å¯åŠ¨å¤šæ¨¡æ€è¿ç®—", use_container_width=True)
    
    # æ¨¡å¼åˆ‡æ¢å¼€å…³
    use_realtime = st.checkbox(
        "ğŸ”¬ å®æ—¶æ¨¡å‹æ¨ç†ï¼ˆè·³è¿‡æ•°æ®åº“ç¼“å­˜ï¼‰", 
        value=False,
        help="å‹¾é€‰åå°†è·³è¿‡é¢„è®¡ç®—æ•°æ®åº“ï¼Œç›´æ¥è¿è¡Œ AI æ¨¡å‹è¿›è¡Œå®æ—¶è®¡ç®—ï¼Œé€Ÿåº¦è¾ƒæ…¢ä½†å¯éªŒè¯æ¨¡å‹çœŸå®æ€§"
    )

    
    # B. è¿ç®—æ ¸å¿ƒé€»è¾‘
    # B. è¿ç®—æ ¸å¿ƒé€»è¾‘
    if btn_predict:
        # === 1. åŠ¨æ€è¿›åº¦æ¡ä½“éªŒ (Dynamic Progress Bar) ===
        progress_bar = st.progress(0, text="å¯åŠ¨æ··åˆä¸“å®¶ç³»ç»Ÿ...")
        import time
        
        # Phase 1: åŠ è½½æ¨¡å‹
        for i in range(30):
            time.sleep(0.01)
            progress_bar.progress(i, text="ğŸ“¡ æ­£åœ¨åŠ è½½ Stacking é›†æˆæ¨¡å‹æƒé‡...")
        
        # Phase 2: ç‰¹å¾å·¥ç¨‹
        for i in range(30, 60):
            time.sleep(0.01)
            progress_bar.progress(i, text="ğŸŒŠ æå– HST æ°´å‹-æ¸©åº¦ç‰¹å¾å› å­...")
            
        # Phase 3: BiLSTM æ¨ç†
        for i in range(60, 85):
            time.sleep(0.02) # ç¨æ…¢ä¸€ç‚¹æ¨¡æ‹Ÿæ·±åº¦å­¦ä¹ è®¡ç®—
            progress_bar.progress(i, text="ğŸ§  BiLSTMç¥ç»ç½‘ç»œæ­£åœ¨è¿›è¡Œæ—¶åºæ¨æ¼”...")
            
        # === æ•°æ®åº“æŸ¥è¯¢æ¨¡å¼ (Database Query Mode) ===
        db_success = False
        extrapolated = False  # æ ‡è®°æ˜¯å¦ä½¿ç”¨äº†å¤–æ¨
        w_s, w_b = 0.6, 0.4  # é»˜è®¤æƒé‡ï¼ˆæ•°æ®åº“æ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
        w_global_s, w_global_b = 0.6, 0.4  # å…¨å±€æƒé‡é»˜è®¤å€¼
        w_local_s, w_local_b = 0.5, 0.5  # å±€éƒ¨æƒé‡é»˜è®¤å€¼
        w_conf_s, w_conf_b = 0.5, 0.5  # ç½®ä¿¡åº¦æƒé‡é»˜è®¤å€¼
        local_history_count = 0  # å±€éƒ¨å†å²è®¡æ•°

        
        if not use_realtime:
            try:
                import sqlite3
                import json
                db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data", "processed", "predictions.db")
                
                if os.path.exists(db_path):
                    conn = sqlite3.connect(db_path)
                    cursor = conn.cursor()
                    
                    # ========================================
                    # è¶…å‡ºæ•°æ®åº“èŒƒå›´æ—¶çš„å¤–æ¨é€»è¾‘ï¼ˆ> 3000å¤©ï¼‰
                    # ========================================
                    if input_t > 3000:
                        st.info("ğŸ”® æ£€æµ‹åˆ°è¶…é•¿æœŸé¢„æµ‹è¯·æ±‚ï¼ˆ>3000å¤©ï¼‰ï¼Œå¯åŠ¨è¶‹åŠ¿å¤–æ¨å¼•æ“...")
                        
                        # æŸ¥è¯¢è¯¥èŠ‚ç‚¹æœ€è¿‘çš„ä¸¤ä¸ªå†å²ç‚¹ï¼ˆç”¨äºè®¡ç®—è¶‹åŠ¿ï¼‰
                        query_trend = """
                            SELECT time_step, final_pred_settlement, final_pred_horizontal,
                                   pred_settlement_std, pred_horizontal_std
                            FROM predictions
                            WHERE ABS(x - ?) < 5 AND ABS(y - ?) < 5
                            ORDER BY time_step DESC
                            LIMIT 2
                        """
                        trend_data = cursor.execute(query_trend, (input_x, input_y)).fetchall()
                        
                        if len(trend_data) >= 2:
                            # æå–æœ€è¿‘ä¸¤ä¸ªç‚¹çš„æ•°æ®
                            t2, s2, h2, std_s2, std_h2 = trend_data[0]  # æœ€æ–°ç‚¹ï¼ˆå¦‚2990å¤©ï¼‰
                            t1, s1, h1, std_s1, std_h1 = trend_data[1]  # æ¬¡æ–°ç‚¹ï¼ˆå¦‚2980å¤©ï¼‰
                            
                            # è®¡ç®—å˜åŒ–ç‡ï¼ˆæ¯å¤©çš„å˜åŒ–é‡ï¼‰
                            dt = t2 - t1
                            if dt > 0:
                                rate_settlement = (s2 - s1) / dt  # mm/day
                                rate_horizontal = (h2 - h1) / dt  # mm/day
                                
                                # å¤–æ¨åˆ°ç›®æ ‡æ—¶é—´
                                time_diff = input_t - t2
                                pred_stacking = s2 + rate_settlement * time_diff
                                pred_lstm = pred_stacking * 1.001  # æ·»åŠ å¾®å°å·®å¼‚
                                final_pred = pred_stacking
                                
                                pred_horiz_stack = h2 + rate_horizontal * time_diff
                                pred_horiz_lstm = pred_horiz_stack * 1.001
                                final_pred_horiz = pred_horiz_stack
                                
                                # ä¸ç¡®å®šæ€§éšæ—¶é—´å¢åŠ 
                                uncertainty_factor = 1 + (time_diff / 1000) * 0.5  # æ¯1000å¤©å¢åŠ 50%
                                pred_std = std_s2 * uncertainty_factor
                                pred_horiz_std = std_h2 * uncertainty_factor
                                
                                pred_lower = final_pred - 2 * pred_std
                                pred_upper = final_pred + 2 * pred_std
                                pred_horiz_lower = final_pred_horiz - 2 * pred_horiz_std
                                pred_horiz_upper = final_pred_horiz + 2 * pred_horiz_std
                                
                                # æ¨¡æ‹Ÿæ³¨æ„åŠ›æƒé‡
                                att_weights = np.random.dirichlet(np.ones(5))
                                
                                db_success = True
                                extrapolated = True
                                validated = False
                                
                                st.success(f"""
âœ… è¶‹åŠ¿å¤–æ¨å®Œæˆ
- åŸºå‡†ç‚¹: T={t2}å¤© â†’ ç›®æ ‡: T={input_t}å¤©
- æ²‰é™å˜åŒ–ç‡: {rate_settlement:.4f} mm/å¤©
- æ°´å¹³ä½ç§»å˜åŒ–ç‡: {rate_horizontal:.4f} mm/å¤©
- å¤–æ¨å¤©æ•°: {time_diff} å¤©
                                """)
                    
                    # ========================================
                    # å¸¸è§„æ•°æ®åº“æŸ¥è¯¢ï¼ˆâ‰¤ 3000å¤©ï¼‰
                    # ========================================
                    if not db_success:
                        # æŸ¥è¯¢æœ€æ¥è¿‘çš„è®°å½•ï¼ˆå®¹é”™èŒƒå›´ï¼šåæ ‡ Â±5mï¼Œæ—¶é—´ Â±10å¤©ï¼‰
                        query = """
                            SELECT pred_settlement_stacking, pred_settlement_lstm, final_pred_settlement,
                                   pred_settlement_std, pred_settlement_lower, pred_settlement_upper,
                                   pred_horizontal_stacking, pred_horizontal_lstm, final_pred_horizontal,
                                   pred_horizontal_std, pred_horizontal_lower, pred_horizontal_upper,
                                   attention_weights, validated
                            FROM predictions
                            WHERE ABS(x - ?) < 5 
                              AND ABS(y - ?) < 5 
                              AND ABS(time_step - ?) < 10
                            ORDER BY (ABS(x - ?) + ABS(y - ?) + ABS(time_step - ?))
                            LIMIT 1
                        """
                        result = cursor.execute(query, (input_x, input_y, input_t, 
                                                       input_x, input_y, input_t)).fetchone()
                        conn.close()
                        
                        if result:
                            # æ‰¾åˆ°äº†æ•°æ®åº“è®°å½•ï¼ˆåŒç›®æ ‡ï¼‰
                            (pred_stacking, pred_lstm, final_pred, pred_std, pred_lower, pred_upper,
                             pred_horiz_stack, pred_horiz_lstm, final_pred_horiz, 
                             pred_horiz_std, pred_horiz_lower, pred_horiz_upper,
                             att_str, validated) = result
                            att_weights = np.array(json.loads(att_str))
                            db_success = True
                            st.success(f"âœ… å·²ä»é¢„æµ‹æ•°æ®åº“æ£€ç´¢ï¼ˆ{'æ·±åº¦éªŒè¯' if validated else 'æ ‡å‡†é¢„æµ‹'}ï¼‰")
            except Exception as db_error:
                st.info(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œåˆ‡æ¢è‡³å®æ—¶è®¡ç®—: {db_error}")
        
        # === çœŸå®æ¨¡å‹æ¨ç† (Real Model Inference) ===
        if not db_success or use_realtime:
            if use_realtime:
                st.info("ğŸ”¬ å®æ—¶ AI æ¨¡å‹æ¨ç†æ¨¡å¼ï¼ˆç»•è¿‡æ•°æ®åº“ï¼‰")

            import pickle
            import torch
            import torch.nn as nn
            
            # å®šä¹‰ BiLSTM æ¨¡å‹ç»“æ„ (éœ€è¦å’Œè®­ç»ƒæ—¶ä¸€è‡´)
            class Attention(nn.Module):
                def __init__(self, hidden_dim):
                    super(Attention, self).__init__()
                    self.W = nn.Linear(hidden_dim, hidden_dim)
                    self.u = nn.Linear(hidden_dim, 1, bias=False)
                def forward(self, x):
                    u = torch.tanh(self.W(x))
                    att_weights = torch.softmax(self.u(u), dim=1)
                    context = torch.sum(att_weights * x, dim=1)
                    return context, att_weights
            
            class AttentionBiLSTM(nn.Module):
                def __init__(self, input_dim, hidden_dim=64):
                    super(AttentionBiLSTM, self).__init__()
                    self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)
                    self.attention = Attention(hidden_dim * 2)
                    self.fc1 = nn.Linear(hidden_dim * 2, 64)
                    self.dropout = nn.Dropout(0.2)
                    self.fc2 = nn.Linear(64, 1)
                def forward(self, x):
                    lstm_out, _ = self.lstm(x)
                    context, att_weights = self.attention(lstm_out)
                    out = torch.relu(self.fc1(context))
                    out = self.dropout(out)
                    out = self.fc2(out)
                    return out, att_weights
            
            # åŠ è½½æ¨¡å‹
            models_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "models")
            
            try:
                # åŠ è½½ Stacking æ¨¡å‹
                with open(os.path.join(models_dir, "stacking_model.pkl"), 'rb') as f:
                    stack_data = pickle.load(f)
                stack_model = stack_data['model']
                scaler_X = stack_data['scaler_X']
                scaler_y = stack_data['scaler_y']
                feature_cols = stack_data['features']
                
                # åŠ è½½ BiLSTM æ¨¡å‹
                bilstm_checkpoint = torch.load(os.path.join(models_dir, "bilstm_model.pth"), map_location='cpu')
                bilstm_model = AttentionBiLSTM(bilstm_checkpoint['input_dim'])
                bilstm_model.load_state_dict(bilstm_checkpoint['model_state_dict'])
                bilstm_model.eval()
                
                # æ„å»ºè¾“å…¥ç‰¹å¾ (X, Y, Time, ä»¥åŠä¸€äº›é»˜è®¤çš„ Lag å€¼)
                # ç”±äºç”¨æˆ·åªè¾“å…¥ X, Y, Timeï¼Œæˆ‘ä»¬éœ€è¦ä»æ•°æ®ä¸­æŸ¥æ‰¾æœ€æ¥è¿‘çš„å†å²å€¼
                # æˆ–è€…ä½¿ç”¨åˆç†çš„é»˜è®¤å€¼
                
                # æŸ¥æ‰¾æ•°æ®ä¸­æœ€æ¥è¿‘çš„èŠ‚ç‚¹
                if df is not None:
                    # æ‰¾åˆ°åæ ‡æœ€æ¥è¿‘çš„èŠ‚ç‚¹
                    dist = np.sqrt((df['X'] - input_x)**2 + (df['Y'] - input_y)**2)
                    closest_idx = dist.idxmin()
                    closest_node_id = df.loc[closest_idx, 'Node_ID']
                    
                    # è·å–è¯¥èŠ‚ç‚¹çš„å†å²æ•°æ®
                    node_history = df[df['Node_ID'] == closest_node_id].sort_values('Time_Step')
                    
                    # ã€å…³é”®ä¿®å¤ã€‘åªä½¿ç”¨ç›®æ ‡æ—¶é—´æ­¥ä¹‹å‰çš„å†å²æ•°æ®ä½œä¸º lag ç‰¹å¾
                    # è¿™æ ·é¢„æµ‹ T=150 æ—¶ï¼Œä½¿ç”¨çš„æ˜¯ T<150 çš„æ•°æ®ï¼Œè€Œä¸æ˜¯ T=1500 çš„æ•°æ®
                    past_history = node_history[node_history['Time_Step'] < input_t]
                    
                    if not past_history.empty:
                        latest_row = past_history.iloc[-1]  # ç›®æ ‡æ—¶é—´ä¹‹å‰çš„æœ€è¿‘æ•°æ®
                        lag_1 = latest_row['Total_Settlement']
                        lag_2 = past_history.iloc[-2]['Total_Settlement'] if len(past_history) > 1 else lag_1
                        lag_3 = past_history.iloc[-3]['Total_Settlement'] if len(past_history) > 2 else lag_2
                        lag_5 = past_history.iloc[-5]['Total_Settlement'] if len(past_history) > 4 else lag_3
                        rolling_mean = past_history['Total_Settlement'].tail(5).mean()
                    elif not node_history.empty:
                        # å¦‚æœç›®æ ‡æ—¶é—´ä¹‹å‰æ²¡æœ‰æ•°æ®ï¼ˆæ¯”å¦‚é¢„æµ‹ T=30ï¼‰ï¼Œä½¿ç”¨æœ€æ—©çš„å·²çŸ¥æ•°æ®
                        earliest_row = node_history.iloc[0]
                        lag_1 = earliest_row['Total_Settlement']
                        lag_2 = lag_3 = lag_5 = rolling_mean = lag_1
                    else:
                        lag_1, lag_2, lag_3, lag_5, rolling_mean = 0, 0, 0, 0, 0
                else:
                    lag_1, lag_2, lag_3, lag_5, rolling_mean = 0, 0, 0, 0, 0
                
                # --- æ ¸å¿ƒä¿®å¤ï¼šå¼•å…¥é€’å½’é€’æ¨æœºåˆ¶ä»¥æå‡å¤–æ¨ç²¾åº¦ ---
                max_time_data = df['Time_Step'].max() if df is not None else 1500
                
                # åˆå§‹åŒ–é€’æ¨å­—å…¸
                if df is not None and closest_node_id:
                    node_hist_all = df[df['Node_ID'] == closest_node_id].sort_values('Time_Step')
                    settle_dict = dict(zip(node_hist_all['Time_Step'].astype(int), node_hist_all['Total_Settlement']))
                else:
                    settle_dict = {}

                # è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨è·å–å†å²å€¼
                def get_safe_val(t, d, default=0.0):
                    t = int(t)
                    if t in d: return d[t]
                    past_keys = [k for k in d.keys() if k <= t]
                    return d[max(past_keys)] if past_keys else default

                # ============================================
                # ä¸‰å±‚æ··åˆåŠ¨æ€æƒé‡ç³»ç»Ÿ
                # ============================================
                
                # === ç¬¬ä¸€å±‚ï¼šå…¨å±€åŸºçº¿æƒé‡ (åŸºäºè®­ç»ƒæ—¶ RMSE) ===
                w_global_s, w_global_b = 0.6, 0.4
                rmse_stacking, rmse_bilstm = 0.001, 0.001  # é»˜è®¤å€¼é¿å…é™¤é›¶
                try:
                    weights_path = os.path.join(models_dir, "fusion_weights.pkl")
                    if os.path.exists(weights_path):
                        with open(weights_path, 'rb') as f:
                            w_data = pickle.load(f)
                        w_global_s = w_data.get('w_stacking', 0.6)
                        w_global_b = w_data.get('w_bilstm', 0.4)
                        rmse_stacking = w_data.get('rmse_stacking', 0.001)
                        rmse_bilstm = w_data.get('rmse_bilstm', 0.001)
                except:
                    pass
                
                # === ç¬¬äºŒå±‚ï¼šå±€éƒ¨åŠ¨æ€æƒé‡ (åŸºäºé‚»åŸŸå†å²å›æµ‹) ===
                w_local_s, w_local_b = 0.5, 0.5
                # ä½¿ç”¨ç›®æ ‡æ—¶é—´ä¹‹å‰çš„å†å²æ•°æ®è®¡ç®—å±€éƒ¨æƒé‡
                local_history = past_history.tail(10) if 'past_history' in dir() and not past_history.empty else pd.DataFrame()
                
                if len(local_history) >= 3:
                    local_errors_s, local_errors_b = [], []
                    for idx, row in local_history.iterrows():
                        # æ„å»ºå†å²ç‚¹ç‰¹å¾
                        hist_lag_1 = row['Total_Settlement']
                        hist_features = np.array([[row['X'], row['Y'], row['Time_Step'], 
                                                   hist_lag_1, hist_lag_1, hist_lag_1, hist_lag_1, hist_lag_1]])
                        hist_scaled = scaler_X.transform(hist_features)
                        
                        # Stacking å›æµ‹
                        try:
                            pred_s_scaled = stack_model.predict(hist_scaled)
                            pred_s = scaler_y.inverse_transform(pred_s_scaled.reshape(-1, 1)).flatten()[0]
                            local_errors_s.append((pred_s - row['Total_Settlement']) ** 2)
                        except:
                            pass
                        
                        # BiLSTM å›æµ‹
                        try:
                            win_sz = bilstm_checkpoint['window_size']
                            seq = np.tile(hist_scaled, (win_sz, 1))
                            tensor = torch.FloatTensor(seq).unsqueeze(0)
                            with torch.no_grad():
                                pred_b_scaled, _ = bilstm_model(tensor)
                            pred_b = scaler_y.inverse_transform(pred_b_scaled.numpy().reshape(-1, 1)).flatten()[0]
                            local_errors_b.append((pred_b - row['Total_Settlement']) ** 2)
                        except:
                            pass
                    
                    # è®¡ç®—å±€éƒ¨ RMSE
                    if local_errors_s and local_errors_b:
                        local_rmse_s = np.sqrt(np.mean(local_errors_s)) + 1e-6
                        local_rmse_b = np.sqrt(np.mean(local_errors_b)) + 1e-6
                        w_local_s = (1/local_rmse_s) / ((1/local_rmse_s) + (1/local_rmse_b))
                        w_local_b = 1 - w_local_s
                
                # è°ƒè¯•ï¼šè®°å½•å±€éƒ¨å†å²æ•°æ®é‡
                local_history_count = len(local_history)
                
                # === ç¬¬ä¸‰å±‚ï¼šç½®ä¿¡åº¦ä¿®æ­£æƒé‡ (åŸºäºé¢„æµ‹åˆ†æ­§åº¦) ===
                # æ³¨æ„ï¼šæ­¤å±‚éœ€è¦åœ¨æ¨¡å‹é¢„æµ‹åè®¡ç®—ï¼Œå…ˆè®¾ç½®å ä½
                w_conf_s, w_conf_b = 0.5, 0.5
                
                # åˆå§‹åŒ–é¢„æµ‹åˆ†æ¨¡å‹å˜é‡ï¼ˆç”¨äº UI ç¨³å®šæ€§ï¼‰
                pred_stacking, pred_lstm = 0.0, 0.0

                # å¦‚æœé¢„æµ‹æ—¶é—´è¶…è¿‡ç°æœ‰æ•°æ®ï¼Œæ‰§è¡Œé€’å½’é€’æ¨
                if input_t > max_time_data:
                    st.info(f"â³ æ£€æµ‹åˆ°å¤–æ¨éœ€æ±‚ (T={input_t} > {max_time_data})ï¼Œæ­£åœ¨æ‰§è¡Œ AI æ·±åº¦é€’å½’æ¨ç†...")
                    
                    steps = range(int(max_time_data) + 10, int(input_t) + 1, 10)
                    
                    # ç¡®ä¿ lag_1 ç­‰åˆå§‹å€¼ä¸ä¸º 0
                    current_l1 = lag_1 if lag_1 != 0 else -0.1
                    current_l2 = lag_2 if lag_2 != 0 else current_l1
                    current_l3 = lag_3 if lag_3 != 0 else current_l2
                    current_l5 = lag_5 if lag_5 != 0 else current_l3
                    current_rm = rolling_mean if rolling_mean != 0 else current_l1
                    
                    for step_t in steps:
                        # æ„å»ºå½“å‰æ­¥ç‰¹å¾
                        step_features = np.array([[input_x, input_y, step_t, current_l1, current_l2, current_l3, current_l5, current_rm]])
                        step_scaled = scaler_X.transform(step_features)
                        
                        # 1. Stacking é¢„æµ‹
                        s_pred_scaled = stack_model.predict(step_scaled)
                        s_p = scaler_y.inverse_transform(s_pred_scaled.reshape(-1, 1)).flatten()[0]
                        
                        # 2. LSTM é¢„æµ‹
                        win_sz = bilstm_checkpoint['window_size']
                        s_seq = np.tile(step_scaled, (win_sz, 1))
                        s_tensor = torch.FloatTensor(s_seq).unsqueeze(0)
                        with torch.no_grad():
                            l_p_scaled, step_att_weights_tensor = bilstm_model(s_tensor)
                        l_p = scaler_y.inverse_transform(l_p_scaled.numpy().reshape(-1, 1)).flatten()[0]
                            
                        # ç†”æ–­å™¨ï¼šé˜²æ­¢æ¨¡å‹é¢„æµ‹å‡ºæ­£å€¼ï¼ˆæ²‰é™å¿…é¡»ä¸ºè´Ÿï¼‰
                        s_p = min(s_p, -0.001)
                        l_p = min(l_p, -0.001)
                        
                        # === å¤–æ¨æ­¥ï¼šç½®ä¿¡åº¦ä¿®æ­£æƒé‡ ===
                        step_div = abs(s_p - l_p) * 1000
                        step_norm_div = min(step_div / 10.0, 1.0)
                        step_trend_diff_s = abs(s_p - current_l1)
                        step_trend_diff_b = abs(l_p - current_l1)
                        if step_trend_diff_s < step_trend_diff_b:
                            step_w_conf_s = 0.5 + 0.3 * step_norm_div
                        else:
                            step_w_conf_s = 0.5 - 0.3 * step_norm_div
                        step_w_conf_b = 1 - step_w_conf_s
                        
                        # ä¸‰å±‚èåˆï¼ˆå¤–æ¨æ¨¡å¼ï¼‰
                        alpha, beta, gamma = 0.4, 0.4, 0.2
                        step_w_s = alpha * w_global_s + beta * w_local_s + gamma * step_w_conf_s
                        step_w_b = alpha * w_global_b + beta * w_local_b + gamma * step_w_conf_b
                        total_step_w = step_w_s + step_w_b
                        step_w_s, step_w_b = step_w_s / total_step_w, step_w_b / total_step_w
                        
                        step_final_m = step_w_s * s_p + step_w_b * l_p
                        
                        # --- æ ¸å¿ƒç‰©ç†çº¦æŸï¼šå¼ºåˆ¶å•è°ƒæ€§ï¼ˆæ²‰é™ä¸å›å¼¹ï¼‰ ---
                        prev_m = settle_dict.get(step_t - 10, current_l1)
                        if abs(step_final_m) < abs(prev_m):
                            step_final_m = prev_m - abs(prev_m) * 0.0005 
                        
                        # æ›´æ–°é€’æ¨é“¾è·¯
                        settle_dict[step_t] = step_final_m
                        current_l1 = step_final_m
                        current_l2 = get_safe_val(step_t - 10, settle_dict, current_l1)
                        current_l3 = get_safe_val(step_t - 20, settle_dict, current_l2)
                        current_l5 = get_safe_val(step_t - 40, settle_dict, current_l3)
                        current_rm = np.mean([settle_dict.get(step_t - i*10, current_l1) for i in range(5)])
                    
                    # æ˜ å°„å›å˜é‡ (mm)
                    final_pred = settle_dict.get(int(input_t), current_l1) * 1000
                    pred_stacking = s_p * 1000
                    pred_lstm = l_p * 1000
                    
                    input_features = step_features 
                    window_size = win_sz
                    att_weights = step_att_weights_tensor.squeeze().numpy()
                    # ä¸º UI å±•ç¤ºä¿å­˜æœ€ç»ˆæƒé‡
                    w_s, w_b = step_w_s, step_w_b
                else:
                    # æ­£å¸¸èŒƒå›´é¢„æµ‹é€»è¾‘
                    input_features = np.array([[input_x, input_y, input_t, lag_1, lag_2, lag_3, lag_5, rolling_mean]])
                    input_scaled = scaler_X.transform(input_features)
                    
                    pred_stack_scaled = stack_model.predict(input_scaled)
                    pred_stacking = scaler_y.inverse_transform(pred_stack_scaled.reshape(-1, 1)).flatten()[0] * 1000
                    
                    window_size = bilstm_checkpoint['window_size']
                    seq_input = np.tile(input_scaled, (window_size, 1))
                    seq_tensor = torch.FloatTensor(seq_input).unsqueeze(0)
                    with torch.no_grad():
                        pred_lstm_scaled, att_weights_tensor = bilstm_model(seq_tensor)
                    pred_lstm = scaler_y.inverse_transform(pred_lstm_scaled.numpy().reshape(-1, 1)).flatten()[0] * 1000
                    att_weights = att_weights_tensor.squeeze().numpy()
                    
                    # === ç¬¬ä¸‰å±‚ï¼šç½®ä¿¡åº¦ä¿®æ­£æƒé‡ (åŸºäºé¢„æµ‹åˆ†æ­§åº¦) ===
                    divergence = abs(pred_stacking - pred_lstm)
                    max_divergence = 10.0  # mmï¼Œç»éªŒé˜ˆå€¼
                    norm_div = min(divergence / max_divergence, 1.0)
                    
                    # åˆ†æ­§å¤§æ—¶ï¼Œæ›´ä¿¡ä»»ä¸å†å²è¶‹åŠ¿ä¸€è‡´çš„æ¨¡å‹
                    trend_diff_s = abs(pred_stacking - lag_1 * 1000)
                    trend_diff_b = abs(pred_lstm - lag_1 * 1000)
                    
                    if trend_diff_s < trend_diff_b:
                        w_conf_s = 0.5 + 0.3 * norm_div
                    else:
                        w_conf_s = 0.5 - 0.3 * norm_div
                    w_conf_b = 1 - w_conf_s
                    
                    # === ä¸‰å±‚æƒé‡èåˆ ===
                    alpha, beta, gamma = 0.4, 0.4, 0.2
                    w_s = alpha * w_global_s + beta * w_local_s + gamma * w_conf_s
                    w_b = alpha * w_global_b + beta * w_local_b + gamma * w_conf_b
                    
                    # å½’ä¸€åŒ–ç¡®ä¿ w_s + w_b = 1
                    total_w = w_s + w_b
                    w_s, w_b = w_s / total_w, w_b / total_w
                    
                    final_pred = w_s * pred_stacking + w_b * pred_lstm
                    
                    # å³ä½¿æ˜¯æ­£å¸¸èŒƒå›´ï¼Œä¹Ÿæ£€æŸ¥ä¸€æ¬¡ç‰©ç†å•è°ƒæ€§
                    if abs(final_pred/1000) < abs(lag_1):
                        final_pred = lag_1 * 1000 - 0.1 
                
                # --- é€šç”¨åå¤„ç†é€»è¾‘ ---
                pred_std = abs(pred_stacking - pred_lstm) / 2
                pred_lower = final_pred - 2 * pred_std
                pred_upper = final_pred + 2 * pred_std
                
                # æ°´å¹³ä½ç§»ï¼ˆå®æ—¶æ¨¡å¼å ä½ï¼‰
                pred_horiz_stack = 0.0
                pred_horiz_lstm = 0.0
                final_pred_horiz = 0.0
                pred_horiz_std = 0.0
                pred_horiz_lower = 0.0
                pred_horiz_upper = 0.0
                
                # ========================================
                # å®æ—¶æ¨ç†ï¼šè®¡ç®—è¿‡ç¨‹å¯è§†åŒ–å±•ç¤º
                # ========================================
                if use_realtime:
                    with st.expander("ğŸ” å®æ—¶æ¨ç†è®¡ç®—è¿‡ç¨‹è¯¦è§£ï¼ˆç‚¹å‡»å±•å¼€æŸ¥çœ‹å†…éƒ¨æœºåˆ¶ï¼‰", expanded=True):
                        st.markdown("##### ğŸ“Š å®Œæ•´æ¨ç†æµç¨‹å¯è§†åŒ–")
                        st.caption("ä»¥ä¸‹å±•ç¤ºæ¨¡å‹ä»è¾“å…¥åˆ°è¾“å‡ºçš„å®Œæ•´è®¡ç®—è¿‡ç¨‹ï¼Œä¾›æ•™å­¦æ¼”ç¤ºä½¿ç”¨")
                        
                        # === æ­¥éª¤1: ç‰¹å¾å·¥ç¨‹ ===
                        st.markdown("---")
                        st.markdown("#### æ­¥éª¤1ï¸âƒ£ ç‰¹å¾å·¥ç¨‹ (Feature Engineering)")
                        
                        col_f1, col_f2 = st.columns([1, 1])
                        with col_f1:
                            st.markdown("**ğŸ”¹ ç”¨æˆ·è¾“å…¥ç‰¹å¾**")
                            input_df = pd.DataFrame({
                                'ç‰¹å¾': ['Xåæ ‡', 'Yåæ ‡', 'æ—¶é—´æ­¥'],
                                'å€¼': [f'{input_x:.2f} m', f'{input_y:.2f} m', f'{input_t} days'],
                                'è¯´æ˜': ['æ°´å¹³ä½ç½®', 'å‚ç›´ä½ç½®', 'é¢„æµ‹æ—¶é—´ç‚¹']
                            })
                            st.dataframe(input_df, hide_index=True, use_container_width=True)
                        
                        with col_f2:
                            st.markdown("**ğŸ”¹ å†å²ç‰¹å¾æå–**")
                            if df is not None and closest_node_id:
                                hist_df = pd.DataFrame({
                                    'ç‰¹å¾ç±»å‹': ['Lag_1', 'Lag_2', 'Lag_3', 'Lag_5', 'Rolling_Mean'],
                                    'å€¼(m)': [f'{lag_1:.6f}', f'{lag_2:.6f}', f'{lag_3:.6f}', 
                                             f'{lag_5:.6f}', f'{rolling_mean:.6f}'],
                                    'è¯´æ˜': ['1æœŸå‰', '2æœŸå‰', '3æœŸå‰', '5æœŸå‰', '5æœŸå‡å€¼']
                                })
                                st.dataframe(hist_df, hide_index=True, use_container_width=True)
                                st.caption(f"ğŸ“ å‚è€ƒèŠ‚ç‚¹: Node {int(closest_node_id)}")
                        
                        # å®Œæ•´ç‰¹å¾å‘é‡å¯è§†åŒ–
                        st.markdown("**ğŸ”¹ å®Œæ•´ç‰¹å¾å‘é‡** (8ç»´è¾“å…¥)")
                        feature_names = ['X', 'Y', 'Time', 'Lag_1', 'Lag_2', 'Lag_3', 'Lag_5', 'RollingMean']
                        feature_values = input_features[0]
                        
                        # ä½¿ç”¨Plotlyåˆ›å»ºç‰¹å¾å‘é‡æŸ±çŠ¶å›¾
                        fig_features = go.Figure(data=[
                            go.Bar(x=feature_names, y=feature_values, 
                                  marker_color=['#00ADB5']*3 + ['#FFD700']*5,
                                  text=[f'{v:.4f}' for v in feature_values],
                                  textposition='outside')
                        ])
                        fig_features.update_layout(
                            title="ç‰¹å¾å‘é‡åˆ†å¸ƒ (Input Vector)",
                            xaxis_title="ç‰¹å¾åç§°",
                            yaxis_title="ç‰¹å¾å€¼",
                            height=250,
                            margin=dict(l=40, r=40, t=50, b=40),
                            paper_bgcolor='#0E1117',
                            plot_bgcolor='#0E1117',
                            font=dict(color='#E0E0E0', size=11)
                        )
                        st.plotly_chart(fig_features, use_container_width=True, config={
                            'displayModeBar': True,
                            'toImageButtonOptions': {'format': 'png', 'scale': 2}
                        })
                        
                        st.info(f"âœ… ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆï¼šMin-Maxå½’ä¸€åŒ–åˆ° [0, 1] åŒºé—´")
                        
                        # === æ­¥éª¤2: æ¨¡å‹æ¨ç† ===
                        st.markdown("---")
                        st.markdown("#### æ­¥éª¤2ï¸âƒ£ åŒæ¨¡å‹å¹¶è¡Œæ¨ç† (Parallel Inference)")
                        
                        model_col1, model_col2 = st.columns(2)
                        
                        with model_col1:
                            st.markdown("**ğŸ“š Stacking é›†æˆæ¨¡å‹**")
                            st.code(f"""
# æ¨¡å‹æ¶æ„
Base Learners: XGBoost + LightGBM + CatBoost
Meta Learner: Ridge Regression

# æ¨ç†è¿‡ç¨‹
input_scaled = scaler.transform(features)
pred_scaled = stacking.predict(input_scaled)
pred_raw = scaler_y.inverse_transform(pred_scaled)
pred_mm = pred_raw * 1000

# è¾“å‡ºç»“æœ
{pred_stacking:.4f} mm
                            """, language="python")
                        
                        with model_col2:
                            st.markdown("**ğŸ§  Attention-BiLSTM ç¥ç»ç½‘ç»œ**")
                            st.code(f"""
# æ¨¡å‹æ¶æ„
BiLSTM (hidden=64, bidirectional=True)
Attention Mechanism
FC Layers (128 â†’ 64 â†’ 1)

# æ¨ç†è¿‡ç¨‹
seq_input = repeat(input_scaled, {window_size})
lstm_out, _ = BiLSTM(seq_input)
context, att_weights = Attention(lstm_out)
pred = FC(context)

# è¾“å‡ºç»“æœ
{pred_lstm:.4f} mm
                            """, language="python")
                        
                        # æ¨¡å‹é¢„æµ‹å¯¹æ¯”
                        st.markdown("**ğŸ”¹ æ¨¡å‹é¢„æµ‹å¯¹æ¯”**")
                        comparison_df = pd.DataFrame({
                            'æ¨¡å‹': ['Stacking', 'BiLSTM'],
                            'é¢„æµ‹å€¼(mm)': [f'{pred_stacking:.4f}', f'{pred_lstm:.4f}'],
                            'å·®å¼‚(mm)': ['-', f'{abs(pred_stacking - pred_lstm):.4f}'],
                            'æƒé‡': [f'{w_s:.1%}', f'{w_b:.1%}']
                        })
                        st.dataframe(comparison_df, hide_index=True, use_container_width=True)
                        
                        # === æ­¥éª¤3: åŠ æƒèåˆ ===
                        st.markdown("---")
                        st.markdown("#### æ­¥éª¤3ï¸âƒ£ ä¸‰å±‚åŠ¨æ€åŠ æƒèåˆ (Hybrid Dynamic Weighting)")
                        
                        # ä¸‰å±‚æƒé‡æ˜ç»†è¡¨æ ¼
                        st.markdown("**ğŸ“Š ä¸‰å±‚æƒé‡åˆ†è§£**")
                        weight_detail_df = pd.DataFrame({
                            'æƒé‡å±‚çº§': ['ğŸŒ å…¨å±€åŸºçº¿', 'ğŸ“ å±€éƒ¨åŠ¨æ€', 'ğŸ¯ ç½®ä¿¡åº¦ä¿®æ­£', 'âš–ï¸ **åŠ æƒèåˆ**'],
                            'Stacking': [f'{w_global_s:.1%}', f'{w_local_s:.1%}', f'{w_conf_s:.1%}', f'**{w_s:.1%}**'],
                            'BiLSTM': [f'{w_global_b:.1%}', f'{w_local_b:.1%}', f'{w_conf_b:.1%}', f'**{w_b:.1%}**'],
                            'è¯´æ˜': ['åŸºäºè®­ç»ƒé›† RMSE', f'åŸºäºé‚»åŸŸ {local_history_count} ä¸ªå†å²ç‚¹å›æµ‹', 'åŸºäºé¢„æµ‹åˆ†æ­§åº¦', '0.4Ã—å…¨å±€ + 0.4Ã—å±€éƒ¨ + 0.2Ã—ç½®ä¿¡']
                        })
                        st.dataframe(weight_detail_df, hide_index=True, use_container_width=True)
                        
                        # æ·»åŠ å±€éƒ¨å†å²çŠ¶æ€è¯´æ˜
                        if local_history_count < 3:
                            st.info(f"âš ï¸ å½“å‰èŠ‚ç‚¹å†å²æ•°æ®è¾ƒå°‘ï¼ˆ{local_history_count} ä¸ªç‚¹ï¼‰ï¼Œå±€éƒ¨æƒé‡ä½¿ç”¨é»˜è®¤å€¼ 50%/50%ã€‚å°è¯•é€‰æ‹©å†å²æ•°æ®æ›´ä¸°å¯Œçš„èŠ‚ç‚¹å°†è·å¾—æ›´åŠ¨æ€çš„æƒé‡åˆ†é…ã€‚")
                        else:
                            st.success(f"âœ… å±€éƒ¨æƒé‡åŸºäº {local_history_count} ä¸ªé‚»åŸŸå†å²ç‚¹åŠ¨æ€è®¡ç®—")
                        
                        st.markdown(f"""
**èåˆå…¬å¼**ï¼š
```
W_final = 0.4 Ã— W_global + 0.4 Ã— W_local + 0.2 Ã— W_confidence
        = 0.4 Ã— {w_global_s:.4f} + 0.4 Ã— {w_local_s:.4f} + 0.2 Ã— {w_conf_s:.4f}
        = {w_s:.4f} (Stacking)

final_pred = {w_s:.4f} Ã— {pred_stacking:.4f} + {w_b:.4f} Ã— {pred_lstm:.4f}
           = {final_pred:.4f} mm
```
                        """)
                        
                        # èåˆè¿‡ç¨‹å¯è§†åŒ–
                        fusion_data = pd.DataFrame({
                            'æ­¥éª¤': ['Stackingè´¡çŒ®', 'BiLSTMè´¡çŒ®', 'æœ€ç»ˆèåˆ'],
                            'å€¼(mm)': [w_s * pred_stacking, w_b * pred_lstm, final_pred]
                        })
                        
                        # èåˆè¿‡ç¨‹å¯è§†åŒ– - å‡çº§ä¸ºé«˜é¢œå€¼æ°´å¹³å †å å›¾
                        fig_fusion = go.Figure()
                        
                        # è®¡ç®—å æ¯”ä¾¿äºæ ‡æ³¨
                        w_stack_pct = w_s * pred_stacking / final_pred if final_pred != 0 else 0
                        w_lstm_pct = w_b * pred_lstm / final_pred if final_pred != 0 else 0
                        
                        fig_fusion.add_trace(go.Bar(
                            name='Stacking è´¡çŒ®',
                            y=['æœ€ç»ˆèåˆ'],
                            x=[w_s * pred_stacking],
                            orientation='h',
                            marker=dict(
                                color='#00ADB5',
                                line=dict(color='#E0E0E0', width=1)
                            ),
                            text=[f'Stacking: {w_s * pred_stacking:.3f} mm ({w_s:.0%})'],
                            textposition='inside',
                            hovertemplate='Stacking è´¡çŒ®: %{x:.4f} mm<extra></extra>'
                        ))
                        
                        fig_fusion.add_trace(go.Bar(
                            name='BiLSTM è´¡çŒ®',
                            y=['æœ€ç»ˆèåˆ'],
                            x=[w_b * pred_lstm],
                            orientation='h',
                            marker=dict(
                                color='#A020F0',
                                line=dict(color='#E0E0E0', width=1)
                            ),
                            text=[f'BiLSTM: {w_b * pred_lstm:.3f} mm ({w_b:.0%})'],
                            textposition='inside',
                            hovertemplate='BiLSTM è´¡çŒ®: %{x:.4f} mm<extra></extra>'
                        ))
                        
                        fig_fusion.update_layout(
                            barmode='stack',
                            title=dict(
                                text=f'ğŸ§© èåˆè¿‡ç¨‹æ‹†è§£ (Total: {final_pred:.4f} mm)',
                                font=dict(size=16)
                            ),
                            height=180,
                            margin=dict(l=20, r=20, t=60, b=20),
                            showlegend=True,
                            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                            paper_bgcolor='#0E1117',
                            plot_bgcolor='#0E1117',
                            font=dict(color='#E0E0E0', size=12),
                            xaxis=dict(showgrid=True, gridcolor='#333', title="è´¡çŒ®å€¼ (mm)"),
                            yaxis=dict(showgrid=False, showticklabels=False)
                        )
                        # æ·»åŠ æœ€ç»ˆå€¼çš„æ–‡å­—è¯´æ˜
                        fig_fusion.add_annotation(
                            x=final_pred, y=0,
                            text=f" {final_pred:.3f} mm",
                            showarrow=False,
                            xanchor="left",
                            font=dict(color="#FFD700", size=14),
                            borderpad=4
                        )
                        st.plotly_chart(fig_fusion, use_container_width=True, config={
                            'displayModeBar': True,
                            'toImageButtonOptions': {'format': 'png', 'scale': 2, 'filename': 'Fusion_Process'}
                        })
                        
                        # === æ­¥éª¤4: ä¸ç¡®å®šæ€§é‡åŒ– ===
                        st.markdown("---")
                        st.markdown("#### æ­¥éª¤4ï¸âƒ£ ä¸ç¡®å®šæ€§é‡åŒ– (Uncertainty Quantification)")
                        
                        st.markdown(f"""
**ç½®ä¿¡åŒºé—´è®¡ç®—**ï¼š
```python
# åŸºäºæ¨¡å‹åˆ†æ­§åº¦ä¼°ç®—
std = |pred_stacking - pred_lstm| / 2
    = |{pred_stacking:.4f} - {pred_lstm:.4f}| / 2
    = {pred_std:.4f} mm

# 95%ç½®ä¿¡åŒºé—´ï¼ˆå‡è®¾æ­£æ€åˆ†å¸ƒï¼‰
lower = final_pred - 2 Ã— std = {final_pred:.4f} - {2*pred_std:.4f} = {pred_lower:.4f} mm
upper = final_pred + 2 Ã— std = {final_pred:.4f} + {2*pred_std:.4f} = {pred_upper:.4f} mm
```
                        """)
                        
                        # ç½®ä¿¡åŒºé—´å¯è§†åŒ–
                        fig_ci = go.Figure()
                        fig_ci.add_trace(go.Scatter(
                            x=[final_pred],
                            y=['é¢„æµ‹å€¼'],
                            mode='markers',
                            marker=dict(size=15, color='#FFD700'),
                            name='æœ€ç»ˆé¢„æµ‹',
                            error_x=dict(
                                type='data',
                                symmetric=False,
                                array=[final_pred - pred_lower],
                                arrayminus=[pred_upper - final_pred],
                                color='#00ADB5',
                                thickness=3
                            )
                        ))
                        fig_ci.update_layout(
                            title='95% ç½®ä¿¡åŒºé—´ (Quantification)',
                            xaxis_title='æ²‰é™é‡ (mm)',
                            height=180,
                            showlegend=False,
                            paper_bgcolor='#0E1117',
                            plot_bgcolor='#0E1117',
                            font=dict(color='#E0E0E0'),
                            margin=dict(l=40, r=40, t=50, b=40)
                        )
                        st.plotly_chart(fig_ci, use_container_width=True, config={
                            'displayModeBar': True,
                            'toImageButtonOptions': {'format': 'png', 'scale': 2}
                        })
                        
                        # === æ€»ç»“ ===
                        st.success(f"""
âœ… **å®æ—¶æ¨ç†å®Œæˆï¼**
- ç‰¹å¾æå–ï¼š8ç»´ â†’ æ ‡å‡†åŒ–
- Stackingé¢„æµ‹ï¼š{pred_stacking:.4f} mm
- BiLSTMé¢„æµ‹ï¼š{pred_lstm:.4f} mm  
- åŠ æƒèåˆï¼š{final_pred:.4f} mm
- ç½®ä¿¡åŒºé—´ï¼š[{pred_lower:.4f}, {pred_upper:.4f}] mm
                        """)
                
                
            except Exception as model_error:
                # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°æ—§çš„éšæœºæ•°é€»è¾‘
                st.warning(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨æ¼”ç¤ºæ¨¡å¼: {model_error}")
                pred_stacking = np.random.normal(5.2, 0.5)
                pred_lstm = np.random.normal(5.8, 0.8)
                final_pred = 0.6 * pred_stacking + 0.4 * pred_lstm
                att_weights = np.random.dirichlet(np.ones(5), size=1)[0]
                
                # æ·»åŠ åŒç›®æ ‡å˜é‡
                pred_std = 0.5
                pred_lower = final_pred - 1.0
                pred_upper = final_pred + 1.0
                pred_horiz_stack = 0.0
                pred_horiz_lstm = 0.0
                final_pred_horiz = 0.0
                pred_horiz_std = 0.0
                pred_horiz_lower = 0.0
                pred_horiz_upper = 0.0

        # ========================================
        # å†å²æ•°æ®å¯¹æ¯”: è‹¥æ—¶é—´æ­¥åœ¨å†å²èŒƒå›´å†…ï¼Œæ˜¾ç¤ºçœŸå®å€¼å¯¹æ¯”
        # ========================================
        actual_settlement = None
        actual_available = False
        actual_node_id = None
        actual_x = None
        actual_y = None
        error_abs = 0.0
        error_pct = 0.0
        rating = ""
        rating_color = "#FFFFFF"
        
        if df is not None:
            max_hist_time = df['Time_Step'].max()
            
            if input_t <= max_hist_time:
                # æŸ¥æ‰¾æœ€æ¥è¿‘çš„å†å²æ•°æ®ç‚¹
                # æ¡ä»¶ï¼šèŠ‚ç‚¹åæ ‡åŒ¹é…ï¼ˆÂ±5må®¹å·®ï¼‰+ æ—¶é—´æ­¥ç²¾ç¡®åŒ¹é…
                matching_rows = df[
                    (df['X'].between(input_x - 5, input_x + 5)) & 
                    (df['Y'].between(input_y - 5, input_y + 5)) & 
                    (df['Time_Step'] == input_t)
                ]
                
                if not matching_rows.empty:
                    # é€‰æ‹©è·ç¦»æœ€è¿‘çš„èŠ‚ç‚¹
                    matching_rows = matching_rows.copy()
                    matching_rows['dist'] = np.sqrt((matching_rows['X'] - input_x)**2 + 
                                                     (matching_rows['Y'] - input_y)**2)
                    best_match = matching_rows.loc[matching_rows['dist'].idxmin()]
                    
                    actual_settlement = best_match['Total_Settlement'] * 1000  # è½¬ä¸º mm
                    actual_node_id = int(best_match['Node_ID'])
                    actual_x = best_match['X']
                    actual_y = best_match['Y']
                    actual_available = True
                    
                    # è®¡ç®—è¯¯å·®æŒ‡æ ‡
                    error_abs = final_pred - actual_settlement
                    if actual_settlement != 0:
                        error_pct = abs(error_abs / actual_settlement) * 100
                    else:
                        error_pct = 0
                    
                    # è¯¯å·®è¯„çº§ï¼ˆæ°´åˆ©å·¥ç¨‹ç­‰çº§åˆ¶åº¦ï¼‰
                    if error_pct < 1:
                        rating = "ä¸€çº§ï¼ˆAçº§ï¼‰"  # åŸ ğŸ†ä¼˜ç§€
                        rating_symbol = "â—"
                        rating_color = "#4A7C59"  # æ°´åˆ©ç»¿
                        rating_en = "Grade A"
                    elif error_pct < 3:
                        rating = "äºŒçº§ï¼ˆBçº§ï¼‰"  # åŸ âœ…è‰¯å¥½
                        rating_symbol = "â—"
                        rating_color = "#0096C7"  # æ°´è“è‰²
                        rating_en = "Grade B"
                    elif error_pct < 5:
                        rating = "ä¸‰çº§ï¼ˆCçº§ï¼‰"  # åŸ âš ï¸ä¸€èˆ¬
                        rating_symbol = "â—"
                        rating_color = "#FB8500"  # è­¦å‘Šæ©™
                        rating_en = "Grade C"
                    else:
                        rating = "å››çº§ï¼ˆDçº§ï¼‰"  # åŸ âŒéœ€å…³æ³¨
                        rating_symbol = "â—"
                        rating_color = "#D62828"  # å±é™©çº¢
                        rating_en = "Grade D"
        
        # æ˜¾ç¤ºå†å²æ•°æ®å¯¹æ¯” UIï¼ˆæ°´åˆ©å·¥ç¨‹é£æ ¼ï¼‰
        if actual_available:
            st.markdown("---")
            st.markdown("### Historical Data Verification (å†å²æ•°æ®éªŒè¯)")
            st.caption(f"Reference Node: #{actual_node_id} @ ({actual_x:.1f}, {actual_y:.1f}) | Time Step: T={input_t} days")
            
            col_actual, col_pred, col_error = st.columns(3)
            
            with col_actual:
                st.metric(
                    label="Ground Truth (çœŸå®æµ‹é‡å€¼)",
                    value=f"{actual_settlement:.2f} mm",
                    help="Source: master_dataset.csv"
                )
            
            with col_pred:
                st.metric(
                    label="Predicted Value (æ¨¡å‹é¢„æµ‹å€¼)",
                    value=f"{final_pred:.2f} mm",
                    delta=f"{error_abs:+.2f} mm",
                    delta_color="inverse"
                )
            
            with col_error:
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, #1E2530, #252D3A); 
                            padding: 16px; border-radius: 6px; text-align: center;
                            border: 2px solid {rating_color};">
                    <div style="color: #CAF0F8; font-size: 13px; font-weight: 600;">Accuracy Class (ç²¾åº¦è¯„çº§)</div>
                    <div style="color: {rating_color}; font-size: 32px; margin: 8px 0;">{rating_symbol}</div>
                    <div style="color: {rating_color}; font-weight: bold; font-size: 16px;">{rating}</div>
                    <div style="color: #90A4AE; font-size: 12px; margin-top: 4px;">{rating_en}</div>
                    <div style="color: #CAF0F8; font-size: 18px; margin-top: 8px; font-weight: bold;">Error: {error_pct:.2f}%</div>
                </div>
                """, unsafe_allow_html=True)
            
            # è¯¯å·®æ¡å½¢å›¾å¯è§†åŒ–ï¼ˆæ°´åˆ©é…è‰²ï¼‰
            fig_error = go.Figure()
            fig_error.add_trace(go.Bar(
                x=['Ground Truth', 'Predicted'],
                y=[actual_settlement, final_pred],
                marker_color=['#0096C7', '#003D7A'],  # æ°´åˆ©è“é…è‰²
                text=[f'{actual_settlement:.2f}', f'{final_pred:.2f}'],
                textposition='outside',
                textfont=dict(color='white')
            ))
            fig_error.update_layout(
                title=f'Prediction vs Ground Truth (Error: {error_abs:+.2f} mm, {error_pct:.2f}%)',
                yaxis_title='Settlement (mm)',
                height=250,
                paper_bgcolor='#0E1117',
                plot_bgcolor='#1E2530',
                font=dict(color='#CAF0F8'),
                margin=dict(l=40, r=40, t=50, b=40)
            )
            st.plotly_chart(fig_error, use_container_width=True)
        
        # Phase 4: ç”ŸæˆæŠ¥å‘Š
        progress_bar.progress(90, text="ğŸ“ AI ä¸“å®¶æ­£åœ¨æ’°å†™åˆ†ææŠ¥å‘Š...")
        
        # 5. LLM æ™ºèƒ½åˆ†æ (SiliconFlow API)
        try:
            from openai import OpenAI
            client = OpenAI(
                api_key="sk-jejoijaihwvytbvsubnerzvozdvlofcrzzcpwytlbeethcwv", # In prod, use st.secrets
                base_url="https://api.siliconflow.cn/v1"
            )
            
            # è®¡ç®—æ¨¡å‹å·®å¼‚åº¦ (ç”¨äºåˆ†æä¸€è‡´æ€§)
            model_diff_s = abs(pred_stacking - pred_lstm)
            model_diff_h = abs(pred_horiz_stack - pred_horiz_lstm)
            consistency_s = "é«˜" if model_diff_s < 1.0 else "ä¸­" if model_diff_s < 2.0 else "ä½"
            consistency_h = "é«˜" if model_diff_h < 1.0 else "ä¸­" if model_diff_h < 2.0 else "ä½"
            
            prompt = (
                f"ä½ æ˜¯ä¸€ä½å¤§åå®‰å…¨ç›‘æµ‹é¢†åŸŸçš„èµ„æ·±æ€»å·¥ç¨‹å¸ˆã€‚æ ¹æ®ä»¥ä¸‹åŒç›®æ ‡é¢„æµ‹æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½å·¥ç¨‹ç ”åˆ¤æŠ¥å‘Šï¼š\n"
                f"- æµ‹ç‚¹åæ ‡: ({input_x}, {input_y}) \n"
                f"- é¢„æµ‹æ—¶é—´: T+{input_t}å¤©\n\n"
                f"**ã€æ²‰é™é¢„æµ‹ã€‘**\n"
                f"- æœ€ç»ˆé›†æˆé¢„æµ‹: {final_pred:.2f} mm\n"
                f"- åˆ†æ¨¡å‹æ•°æ®: Stacking={pred_stacking:.2f}mm (æƒé‡{w_s:.1%}), BiLSTM={pred_lstm:.2f}mm (æƒé‡{w_b:.1%}) | ä¸€è‡´æ€§={consistency_s}\n"
                + (f"- âœ… å†å²éªŒè¯: çœŸå®å€¼={actual_settlement:.2f}mm, è¯¯å·®={error_abs:+.2f}mm ({error_pct:.2f}%), è¯„çº§={rating}\n" if actual_available else "")
                + f"\n**ã€æ°´å¹³ä½ç§»é¢„æµ‹ã€‘**\n"
                f"- æœ€ç»ˆé›†æˆé¢„æµ‹: {final_pred_horiz:.2f} mm\n"
                f"- åˆ†æ¨¡å‹æ•°æ®: Stacking={pred_horiz_stack:.2f}mm, BiLSTM={pred_horiz_lstm:.2f}mm (ä¸€è‡´æ€§={consistency_h})\n\n"
                f"æŠ¥å‘Šæ’°å†™è¦æ±‚ï¼ˆç²¾ç‚¼HTMLé£æ ¼ï¼‰ï¼š\n"
                f"1. **åŒç›®æ ‡ä¼šè¯Š**: åˆ†ææ²‰é™å’Œæ°´å¹³ä½ç§»çš„å…³è”æ€§ã€‚ä¾‹å¦‚ï¼Œæ²‰é™å¢å¤§æ—¶æ°´å¹³ä½ç§»æ˜¯å¦åŒæ­¥ï¼Ÿ\n"
                + (f"2. **æ¨¡å‹éªŒè¯è¯„ä»·**: ç»“åˆå†å²éªŒè¯ç»“æœè¯„ä»·æ¨¡å‹å¯ä¿¡åº¦ã€‚\n" if actual_available else "")
                + f"3. **æˆå› åˆ†æ**: ç»“åˆä¸¤ä¸ªæŒ‡æ ‡è§£é‡Šåä½“çŠ¶æ€ã€‚\n"
                f"4. **è¿ç»´å»ºè®®**: ç»™å‡ºå…·ä½“è¡ŒåŠ¨æŒ‡å—ã€‚\n"
                f"5. è¯­æ°”ä¸“ä¸šã€å®¢è§‚ã€‚ä¸è¦ç”¨ markdown æ ‡é¢˜ï¼Œç›´æ¥åˆ†æ®µè¾“å‡ºæ­£æ–‡ã€‚"
            )
            
            response = client.chat.completions.create(
                model="Qwen/Qwen2.5-7B-Instruct",  # æ›´å¿«çš„æ¨¡å‹
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å¤§åå®‰å…¨ç›‘æµ‹ä¸“å®¶ã€‚ç”¨100å­—ä»¥å†…ç®€æ´åˆ†æã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=200,  # é™åˆ¶é•¿åº¦æé«˜é€Ÿåº¦
                stream=False
            )
            llm_analysis = response.choices[0].message.content
        except Exception as e:
            llm_analysis = (
                f"âš ï¸ **æ™ºèƒ½åˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨**<br>"
                f"é”™è¯¯ä¿¡æ¯: {str(e)}<br>"
                f"**ç¦»çº¿åˆ†æ**: é¢„æµ‹æ²‰é™ {final_pred:.2f} mmï¼Œå»ºè®®å…³æ³¨å±€éƒ¨å˜å½¢è¶‹åŠ¿ã€‚"
            )
        
        # å®Œæˆ
        progress_bar.progress(100, text="âœ… åˆ†æå®Œæˆï¼")
        time.sleep(0.5)
        progress_bar.empty() # å¯é€‰ï¼šå®Œæˆåéšè—è¿›åº¦æ¡
        
        # å­˜å…¥ Session State ä¾›æŠ¥å‘Šç”Ÿæˆä½¿ç”¨
        st.session_state['latest_pred'] = final_pred
        st.session_state['latest_analysis'] = llm_analysis
        st.session_state['latest_node'] = f"{int(max_node)}" if 'max_node' in locals() else "N/A"
        
        # ========================================
        # ä¿å­˜åˆ°æ•°æ®åº“åŠŸèƒ½ï¼ˆä»…å®æ—¶æ¨ç†æ¨¡å¼ï¼‰
        # ========================================
        if use_realtime:
            st.markdown("---")
            st.markdown("### ğŸ’¾ ä¿å­˜å®æ—¶è®¡ç®—ç»“æœ")
            st.caption("å°†æœ¬æ¬¡å®æ—¶æ¨ç†ç»“æœæ°¸ä¹…ä¿å­˜åˆ°æ‚¨çš„ä¸ªäººé¢„æµ‹å†å²æ•°æ®åº“")
            
            save_col1, save_col2, save_col3 = st.columns([2, 1, 1])
            
            with save_col1:
                user_notes = st.text_input(
                    "ğŸ“ æ·»åŠ å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰",
                    placeholder="ä¾‹å¦‚ï¼šåé¡¶å…³é”®ç‚¹ä½ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨...",
                    help="ä¸ºè¿™æ¬¡é¢„æµ‹æ·»åŠ å¤‡æ³¨è¯´æ˜ï¼Œæ–¹ä¾¿æ—¥åæŸ¥é˜…"
                )
            
            with save_col2:
                st.write("")  # Spacer
                btn_save = st.button(
                    "ğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“", 
                    type="primary",
                    use_container_width=True,
                    help="ä¿å­˜æœ¬æ¬¡é¢„æµ‹ç»“æœåŠæ‰€æœ‰å‚æ•°"
                )
            
            with save_col3:
                st.write("")  # Spacer
                btn_view_history = st.button(
                    "ğŸ“Š æŸ¥çœ‹å†å²",
                    use_container_width=True,
                    help="æŸ¥çœ‹æ‰€æœ‰å·²ä¿å­˜çš„é¢„æµ‹è®°å½•"
                )
            
            # å¤„ç†ä¿å­˜æ“ä½œ
            if btn_save:
                try:
                    # æ›´æ–°å¯¼å…¥è·¯å¾„ï¼ˆæ–‡ä»¶å·²ç§»è‡³scriptsç›®å½•ï¼‰
                    import sys
                    if 'scripts' not in sys.path:
                        sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'scripts'))
                    from user_prediction_manager import UserPredictionManager
                    manager = UserPredictionManager()
                    
                    # å‡†å¤‡é¢„æµ‹æ•°æ®
                    prediction_data = {
                        'input_x': float(input_x),
                        'input_y': float(input_y),
                        'input_time': int(input_t),
                        'pred_stacking': float(pred_stacking),
                        'pred_bilstm': float(pred_lstm),
                        'final_prediction': float(final_pred),
                        'std_deviation': float(pred_std),
                        'confidence_lower': float(pred_lower),
                        'confidence_upper': float(pred_upper),
                        'weight_stacking': float(w_s) if 'w_s' in locals() else 0.5,
                        'weight_bilstm': float(w_b) if 'w_b' in locals() else 0.5,
                        'user_notes': user_notes
                    }
                    
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    record_id = manager.save_prediction(prediction_data)
                    
                    if record_id:
                        st.success(f"âœ… ä¿å­˜æˆåŠŸï¼è®°å½•ID: {record_id}")
                        st.balloons()  # æ’­æ”¾åº†ç¥åŠ¨ç”»
                    else:
                        st.warning("âš ï¸ è¯¥é¢„æµ‹ç»“æœå·²å­˜åœ¨ï¼ˆç›¸åŒåæ ‡å’Œæ—¶é—´ï¼‰ï¼Œæœªé‡å¤ä¿å­˜")
                
                except Exception as save_error:
                    st.error(f"âŒ ä¿å­˜å¤±è´¥: {save_error}")
            
            # å¤„ç†æŸ¥çœ‹å†å²æ“ä½œ
            if btn_view_history:
                try:
                    import sys
                    if 'scripts' not in sys.path:
                        sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'scripts'))
                    from user_prediction_manager import UserPredictionManager
                    manager = UserPredictionManager()
                    
                    recent = manager.get_recent_predictions(limit=20)
                    stats = manager.get_statistics()
                    
                    if recent:
                        st.markdown("#### ğŸ“œ æœ€è¿‘20æ¡é¢„æµ‹è®°å½•")
                        
                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        stat_col1, stat_col2, stat_col3 = st.columns(3)
                        with stat_col1:
                            st.metric("æ€»è®°å½•æ•°", f"{stats['total_count']}")
                        with stat_col2:
                            st.metric("å¹³å‡é¢„æµ‹", f"{stats.get('avg_prediction', 0):.2f} mm")
                        with stat_col3:
                            st.metric("é¢„æµ‹èŒƒå›´", f"[{stats.get('min_prediction', 0):.1f}, {stats.get('max_prediction', 0):.1f}]")
                        
                        # æ˜¾ç¤ºè®°å½•è¡¨æ ¼
                        history_df = pd.DataFrame(recent, columns=[
                            'ID', 'æ—¶é—´', 'Xåæ ‡', 'Yåæ ‡', 'æ—¶é—´æ­¥', 
                            'æœ€ç»ˆé¢„æµ‹(mm)', 'æ ‡å‡†å·®', 'å¤‡æ³¨'
                        ])
                        st.dataframe(
                            history_df,
                            hide_index=True,
                            use_container_width=True,
                            column_config={
                                "ID": st.column_config.NumberColumn("ID", width="small"),
                                "æ—¶é—´": st.column_config.TextColumn("æ—¶é—´", width="medium"),
                                "Xåæ ‡": st.column_config.NumberColumn("Xåæ ‡", format="%.2f m"),
                                "Yåæ ‡": st.column_config.NumberColumn("Yåæ ‡", format="%.2f m"),
                                "æœ€ç»ˆé¢„æµ‹(mm)": st.column_config.NumberColumn("æœ€ç»ˆé¢„æµ‹", format="%.4f mm"),
                                "æ ‡å‡†å·®": st.column_config.NumberColumn("æ ‡å‡†å·®", format="%.4f"),
                                "å¤‡æ³¨": st.column_config.TextColumn("å¤‡æ³¨", width="large")
                            }
                        )
                    else:
                        st.info("ğŸ“­ æš‚æ— ä¿å­˜çš„é¢„æµ‹è®°å½•ï¼Œå¼€å§‹æ‚¨çš„ç¬¬ä¸€æ¬¡ä¿å­˜å§ï¼")
                
                except Exception as history_error:
                    st.error(f"âŒ åŠ è½½å†å²è®°å½•å¤±è´¥: {history_error}")
    
    
        # C. ç»“æœå±•ç¤ºåŒºï¼ˆåŒç›®æ ‡åŒåˆ—å¸ƒå±€ï¼‰
        st.markdown("### ğŸ¯ åŒç›®æ ‡é¢„æµ‹ç»“æœ")
        
        # ä½¿ç”¨2åˆ—å¸ƒå±€å±•ç¤ºåŒç›®æ ‡
        pred_col1, pred_col2 = st.columns(2)
        
        with pred_col1:
            st.markdown("#### ğŸ“‰ ç´¯è®¡æ²‰é™ (Settlement)")
            st.metric("æœ€ç»ˆé¢„æµ‹", f"{final_pred:.2f} mm", 
                     delta=f"Stacking: {pred_stacking:.2f}mm",
                     delta_color="inverse")
            st.metric("BiLSTM é¢„æµ‹", f"{pred_lstm:.2f} mm", 
                     delta=f"ç½®ä¿¡åŒºé—´: [{pred_lower:.1f}, {pred_upper:.1f}]")
            st.progress(0.95, text="æ¨¡å‹ç½®ä¿¡åº¦: 95%")
            
        with pred_col2:
            st.markdown("#### â†”ï¸ é¡ºæ²³å‘ä½ç§» (Horizontal)")
            st.metric("æœ€ç»ˆé¢„æµ‹", f"{final_pred_horiz:.2f} mm", 
                     delta=f"Stacking: {pred_horiz_stack:.2f}mm")
            st.metric("BiLSTM é¢„æµ‹", f"{pred_horiz_lstm:.2f} mm", 
                     delta=f"ç½®ä¿¡åŒºé—´: [{pred_horiz_lower:.1f}, {pred_horiz_upper:.1f}]")
            st.progress(0.92, text="æ¨¡å‹ç½®ä¿¡åº¦: 92%")
        
        # ä¸‹é¢ä¿ç•™åŸæœ‰çš„ XAI å’Œåˆ†ææŠ¥å‘Šå±•ç¤º
        res_c2, res_c3 = st.columns([1, 1])
            
        with res_c2:
            st.markdown("#### ğŸ§  XAI å¯è§£é‡Šæ€§")
            # ç»˜åˆ¶ Attention Bar Chart
            fig_att = go.Figure(go.Bar(
                x=[f"t-{i}" for i in range(10, 0, -1)],
                y=att_weights,
                marker_color=att_weights,
                marker_colorscale='Viridis'
            ))
            fig_att.update_layout(
                title="Time-Attention Weights (æ—¶åºæ³¨æ„åŠ›æƒé‡)",
                xaxis_title="å†å²çª—å£ (è¿‡å»10å¤©)",
                yaxis_title="å½±å“æƒé‡",
                height=300,
                margin=dict(l=40, r=40, t=50, b=40),
                paper_bgcolor='#0E1117',
                plot_bgcolor='#0E1117',
                font=dict(color='#E0E0E0')
            )
            st.plotly_chart(fig_att, use_container_width=True, config={
                'displayModeBar': True,
                'toImageButtonOptions': {'format': 'png', 'scale': 2}
            })
            
        with res_c3:
            st.markdown("#### ğŸ¤– AI ä¸“å®¶åˆ†ææŠ¥å‘Š")
            # === 2. ç¾åŒ–æŠ¥å‘Š UI (Styled Report Card) ===
            # Fix: Calculate formatted string outside f-string to avoid backslash error
            formatted_analysis = llm_analysis.replace('\n', '<br>')
            
            # è·å–RMSEæ•°æ®ç”¨äºæƒé‡è®¡ç®—è¯´æ˜ï¼ˆw_s, w_bå·²åœ¨ä¸Šæ–¹åŠ¨æ€è®¡ç®—ï¼‰
            rmse_s, rmse_b = None, None
            try:
                weights_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "models", "fusion_weights.pkl")
                if os.path.exists(weights_path):
                    with open(weights_path, 'rb') as f:
                        weights_data = pickle.load(f)
                    # åªè·å–RMSEç”¨äºå±•ç¤ºï¼Œä¸è¦†ç›–w_så’Œw_b
                    rmse_s = weights_data.get('rmse_stacking', None)
                    rmse_b = weights_data.get('rmse_bilstm', None)
            except:
                pass
            
            # ç¡®ä¿Ÿw_så’Œw_bå·²å®šä¹‰ï¼ˆå¦‚æœç”¨æˆ·è¿˜æ²¡ç‚¹å‡»é¢„æµ‹æŒ‰é’®ï¼‰
            if 'w_s' not in locals() or 'w_b' not in locals():
                w_s, w_b = 0.6, 0.4  # é»˜è®¤æƒé‡
            
            # è®¡ç®—åŠ æƒè´¡çŒ®åº¦
            contrib_stacking = w_s * pred_stacking
            contrib_bilstm = w_b * pred_lstm
            
            # åŠ¨æ€ç”ŸæˆåŠ æƒèåˆå¯è§†åŒ– (HTML/CSS)
            # è®¡ç®—å¯è§†åŒ–æ¯”ä¾‹
            max_val = max(pred_stacking, pred_lstm, final_pred)
            if max_val > 0:
                bar_stack = (pred_stacking / max_val) * 100
                bar_lstm = (pred_lstm / max_val) * 100
                bar_final = (final_pred / max_val) * 100
            else:
                bar_stack = bar_lstm = bar_final = 50
            
            report_html = f"""
<div style="background-color: #1E2530; border-left: 5px solid #00ADB5; padding: 20px; border-radius: 5px; box-shadow: 0 4px 6px rgba(0,0,0,0.3); font-family: 'Segoe UI', sans-serif; color: #E0E0E0;">
<div style="display: flex; align-items: center; margin-bottom: 10px;">
<span style="font-size: 20px; margin-right: 10px;">ğŸ©º</span>
<h4 style="margin: 0; color: #00ADB5;">åŠ¨æ€åŠ æƒèåˆ (Dynamic Weighted Fusion)</h4>
</div>

<!-- åŠ æƒèåˆå¯è§†åŒ– -->
<div style="background: #2D333B; padding: 12px; border-radius: 4px; margin-bottom: 15px; font-size: 12px;">
<!-- Stacking è´¡çŒ® -->
<div style="margin-bottom: 8px;">
<div style="display: flex; justify-content: space-between; margin-bottom: 3px;">
<span>ğŸ“š Stacking <span style="color: #888;">(æƒé‡: {w_s:.1%})</span></span>
<span><b>{pred_stacking:.2f}</b> mm â†’ <span style="color: #00ADB5;">{contrib_stacking:.2f}</span></span>
</div>
<div style="height: 20px; background: #1a1f28; border-radius: 3px; position: relative; overflow: hidden;">
<div style="height: 100%; width: {bar_stack}%; background: linear-gradient(90deg, #00ADB5, #00d4db); display: flex; align-items: center; justify-content: flex-end; padding-right: 5px; color: #fff; font-weight: bold; font-size: 10px;"></div>
</div>
</div>

<!-- BiLSTM è´¡çŒ® -->
<div style="margin-bottom: 8px;">
<div style="display: flex; justify-content: space-between; margin-bottom: 3px;">
<span>ğŸ§  BiLSTM <span style="color: #888;">(æƒé‡: {w_b:.1%})</span></span>
<span><b>{pred_lstm:.2f}</b> mm â†’ <span style="color: #A020F0;">{contrib_bilstm:.2f}</span></span>
</div>
<div style="height: 20px; background: #1a1f28; border-radius: 3px; position: relative; overflow: hidden;">
<div style="height: 100%; width: {bar_lstm}%; background: linear-gradient(90deg, #A020F0, #d020f0); display: flex; align-items: center; justify-content: flex-end; padding-right: 5px; color: #fff; font-weight: bold; font-size: 10px;"></div>
</div>
</div>

<!-- åˆ†éš”çº¿ -->
<div style="height: 1px; background: linear-gradient(90deg, transparent, #555, transparent); margin: 10px 0;"></div>

<!-- æœ€ç»ˆèåˆç»“æœ -->
<div>
<div style="display: flex; justify-content: space-between; margin-bottom: 3px;">
<span>âš¡ æœ€ç»ˆèåˆ <span style="color: #888;">(weighted sum)</span></span>
<span style="color: #FFD700; font-weight: bold; font-size: 14px;">{final_pred:.2f} mm</span>
</div>
<div style="height: 24px; background: #1a1f28; border-radius: 3px; position: relative; overflow: hidden; border: 1px solid #FFD700;">
<div style="height: 100%; width: {bar_final}%; background: linear-gradient(90deg, #FFD700, #FFA500); display: flex; align-items: center; justify-content: center; color: #000; font-weight: bold; font-size: 11px;">âœ“</div>
</div>
</div>

<div style="text-align: center; color: #888; margin-top: 8px; font-size: 10px;">
å…¬å¼: {final_pred:.2f} = {w_s:.2f} Ã— {pred_stacking:.2f} + {w_b:.2f} Ã— {pred_lstm:.2f}
</div>
"""

            
            report_html += f"""

<!-- AI åˆ†æ -->
<div style="font-size: 13px; line-height: 1.6; opacity: 0.9;">
{formatted_analysis}
</div>
</div>
"""
            st.markdown(report_html, unsafe_allow_html=True)

# --- é‡ç‚¹éƒ¨ä½å…¨ç”Ÿå‘½å‘¨æœŸè¿½è¸ª (Key Node Tracker) ---
st.markdown("---")
st.header("ğŸ“ˆ é‡ç‚¹éƒ¨ä½å…¨ç”Ÿå‘½å‘¨æœŸè¿½è¸ª (Lifecycle Tracker)")

if df is not None:
    # ä»»åŠ¡ä¹¦æŒ‡å®šèŠ‚ç‚¹
    # è·å–æ‰€æœ‰èŠ‚ç‚¹åˆ—è¡¨ (ç”¨äºæœç´¢)
    all_nodes_sorted = sorted(df['Node_ID'].unique())
    
    # é»˜è®¤æ¨èèŠ‚ç‚¹ (Key Nodes)
    default_nodes = [369, 385, 416, 91, 27]
    
    # æ„é€ ä¼˜å…ˆçº§åˆ—è¡¨: æ¨èèŠ‚ç‚¹ç½®é¡¶ + å…¶ä½™èŠ‚ç‚¹æŒ‰åºæ’åˆ—
    # ç¡®ä¿é»˜è®¤èŠ‚ç‚¹åœ¨æ•°æ®ä¸­å­˜åœ¨
    priority_nodes = [n for n in default_nodes if n in all_nodes_sorted]
    other_nodes = [n for n in all_nodes_sorted if n not in priority_nodes]
    
    # åˆå¹¶é€‰é¡¹åˆ—è¡¨ (æ¨èçš„æ’å‰é¢)
    options_list = priority_nodes + other_nodes
    
    # äº¤äº’å¼é€‰æ‹©å™¨ (Interactive Selector)
    selected_nodes = st.multiselect(
        "ğŸ¯ é€‰æ‹©ç›‘æµ‹ç‚¹ä½ (Select Nodes to Track)",
        options=options_list,
        default=priority_nodes,
        help="æ¨èé‡ç‚¹éƒ¨ä½å·²ç½®é¡¶æ˜¾ç¤ºã€‚æ‚¨å¯åœ¨ä¸‹æ‹‰æ¡†ä¸­æœç´¢å¹¶æ·»åŠ ä»»æ„èŠ‚ç‚¹ã€‚",
        format_func=lambda x: f"Node {int(x)}" if x == int(x) else f"Node {x}"
    )
    
    if selected_nodes:
        tracker_df = df[df['Node_ID'].isin(selected_nodes)].copy()
        
        # ç»˜åˆ¶å¤šçº¿å›¾
        fig_track = px.line(
            tracker_df, 
            x="Time_Step", 
            y="Total_Settlement", 
            color="Node_ID",
            title="å…³é”®èŠ‚ç‚¹ç´¯è®¡æ²‰é™è¿‡ç¨‹çº¿ (Cumulative Settlement Process)",
            labels={"Time_Step": "Time (Days)", "Total_Settlement": "Settlement (m)", "Node_ID": "Node"},
            markers=False # æ•°æ®ç‚¹å¯†é›†æ—¶å…³é—­æ ‡è®°æ›´æ¸…æ™°ä»¥å±•ç¤ºè¶‹åŠ¿
        )
        
        # æ·»åŠ äº¤äº’è”åŠ¨çº¢çº¿ (Current Time Indicator)
        fig_track.add_vline(x=current_time, line_width=2, line_dash="dash", line_color="red", annotation_text="Current Time")
        
        fig_track.update_layout(
            height=450,
            hovermode="x unified",
            xaxis=dict(showgrid=False),
            yaxis=dict(showgrid=True, gridcolor='#333'),
            # å°†èƒŒæ™¯è‰²ç»Ÿä¸€
            paper_bgcolor='#0E1117', 
            plot_bgcolor='#0E1117',
            font=dict(color='#E0E0E0'),
            legend=dict(orientation="h", y=1.1, x=0)
        )
        
        # é…ç½®ä¸‹è½½æŒ‰é’®åŠŸèƒ½ (Enable High-Res Download with Background)
        config = {
            'displayModeBar': True,
            'displaylogo': False,
            'toImageButtonOptions': {
                'format': 'png', 
                'filename': f'Dam_Lifecycle_Tracker_{datetime.now().strftime("%Y%m%d")}_T{current_time}',
                'height': 900,
                'width': 1600,
                'scale': 2 # High resolution download
            },
            'modeBarButtonsToRemove': ['lasso2d', 'select2d']
        }
        
        st.plotly_chart(fig_track, use_container_width=True, config=config)
        st.caption(f"ğŸ’¡ æç¤ºï¼šç‚¹å‡»å›¾è¡¨å³ä¸Šè§’çš„ç…§ç›¸æœºå›¾æ ‡ ğŸ“· å³å¯ä¸‹è½½é«˜æ¸…æ›²çº¿å›¾ã€‚å½“å‰å·²é€‰ä¸­ {len(selected_nodes)} ä¸ªå…³é”®èŠ‚ç‚¹ã€‚")
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨ä¸Šæ–¹ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹©è‡³å°‘ä¸€ä¸ªèŠ‚ç‚¹è¿›è¡Œè¿½è¸ªã€‚")

# --- è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆå™¨ (Sidebar Bottom) ---
with st.sidebar:
    st.markdown("---")
    st.markdown("### ğŸ“‘ æŠ¥å‘Šç”Ÿæˆ")
    
    # å‡†å¤‡æŠ¥å‘Šæ•°æ®
    # å¦‚æœè¿˜æ²¡æœ‰ç‚¹å‡»è¿‡ AI é¢„æµ‹ï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼
    rpt_pred = st.session_state.get('latest_pred', 0.0)
    rpt_analysis = st.session_state.get('latest_analysis', "ï¼ˆæš‚æ—  AI åˆ†æï¼Œè¯·å…ˆè¿è¡Œé¢„æµ‹æ¨¡å—ï¼‰")
    
    # è·å–ä¹‹å‰è®¡ç®—çš„ KPI (éœ€è¦è®¿é—®å±€éƒ¨å˜é‡ï¼Œå¦‚æœåœ¨ sidebar æœ€åè¿è¡Œ block å¯ä»¥è®¿é—®åˆ°ä¸Šæ–¹å®šä¹‰çš„å˜é‡å—ï¼Ÿ
    # åœ¨ Streamlit ä¸­ï¼Œå¦‚æœå˜é‡æ˜¯åœ¨ä¸»è„šæœ¬æµç¨‹ä¸­å®šä¹‰çš„ï¼Œåç»­ä»£ç å¯ä»¥è®¿é—®ã€‚
    # ä¸ºäº†ç¨³å¥ï¼Œä½¿ç”¨ .get æˆ–é»˜è®¤å€¼)
    rpt_max_settle = f"{max_settle_mm:.2f}" if 'max_settle_mm' in locals() else "N/A"
    rpt_max_node = f"{int(max_node)}" if 'max_node' in locals() else "N/A"
    rpt_rate = avg_rate_str if 'avg_rate_str' in locals() else "N/A"
    rpt_score = f"{health_score:.1f}" if 'health_score' in locals() else "N/A"
    
    report_text = f"""# æ²³æµ·å¤§å­¦åœŸçŸ³åæ•°å­—å­ªç”Ÿç›‘æµ‹å‘¨æŠ¥
**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ç›‘æµ‹æ—¶é—´æ­¥**: ç¬¬ {current_time} å¤©

## 1. æ ¸å¿ƒæŒ‡æ ‡æ‘˜è¦
- **æœ€å¤§æ²‰é™é‡**: {rpt_max_settle} mm (ä½äºèŠ‚ç‚¹ {rpt_max_node})
- **å¹³å‡å˜å½¢é€Ÿç‡**: {rpt_rate}
- **æ•´ä½“å¥åº·è¯„åˆ†**: {rpt_score} åˆ†

## 2. AI æ™ºèƒ½åˆ†æç»“è®º
- **æ··åˆæ¨¡å‹é¢„æµ‹å€¼**: {rpt_pred:.2f} mm
- **ä¸“å®¶å»ºè®®**:
{rpt_analysis}

---
*Based on æ²³æµ·å¤§å­¦Â·æ°´åˆ©å¤§æ•°æ®å’Œä¿¡æ¯æŒ–æ˜æŠ€æœ¯è¯¾ç¨‹è®¾è®¡ | Developer: ç« æ¶µç¡•*
"""
    
    st.download_button(
        label="ğŸ“„ ä¸‹è½½ç›‘æµ‹å‘¨æŠ¥ (Markdown)",
        data=report_text,
        file_name=f"Dam_Monitor_Report_T{current_time}.md",
        mime="text/markdown"
    )

# --- æ¨¡å‹æ€§èƒ½è¯„ä¼°æ¨¡å— (New) ---
st.markdown("---")
st.markdown("## ğŸ“ˆ æ¨¡å‹æ€§èƒ½ç»¼åˆè¯„ä¼° (Model Evaluation)")

with st.expander("æŸ¥çœ‹è¯¦ç»†æ¨¡å‹å¯¹æ¯”æ•°æ®", expanded=True):
    col_eval_1, col_eval_2 = st.columns([1, 1])
    
    with col_eval_1:
        st.markdown("#### ğŸ“Š å„æ¨¡å‹é‡åŒ–æŒ‡æ ‡å¯¹æ¯”")
        eval_data = {
            "æ¨¡å‹ (Model)": ["MLR (å¤šå…ƒçº¿æ€§å›å½’)", "SVR (æ”¯æŒå‘é‡å›å½’)", "å•ç‹¬ LSTM", "Stacking é›†æˆ", "å•ç‹¬ BiLSTM", "æœ¬æ–‡èåˆæ¨¡å‹ (Hybrid)"],
            "RMSE (mm)": [0.01, 16.80, 91.47, 1.34, 89.98, 2.02],
            "RÂ² Score": [1.0000, 0.9637, -0.08, 0.9998, -0.04, 0.9995],
            "ç»¼åˆè¯„ä»·": ["è¿‡æ‹Ÿåˆ (Overfit)", "è‰¯å¥½ (Good)", "è¾ƒå·® (Poor)", "ä¼˜ç§€ (Excellent)", "è¾ƒå·® (Poor)", "ä¼˜ç§€ (Excellent)"]
        }
        df_eval = pd.DataFrame(eval_data)
        st.dataframe(
            df_eval.style.applymap(
                lambda x: "background-color: #2E7D32" if "ä¼˜ç§€" in str(x) else ("background-color: #C62828" if "è¾ƒå·®" in str(x) else ""), 
                subset=["ç»¼åˆè¯„ä»·"]
            ).format({"RMSE (mm)": "{:.2f}", "RÂ² Score": "{:.4f}"}),
            use_container_width=True
        )
        st.caption("æ³¨ï¼šå•ç‹¬æ·±åº¦å­¦ä¹ æ¨¡å‹(LSTM/BiLSTM)åœ¨ä¸¥æ ¼çš„æ—¶åºåˆ’åˆ†(Out-of-Time)æµ‹è¯•ä¸‹æ³›åŒ–å›°éš¾ï¼Œå¯¼è‡´RÂ²ä¸ºè´Ÿï¼Œè¿™æ­£æ˜¯å¼•å…¥Stackingé›†æˆçš„å¿…è¦æ€§ã€‚")

    with col_eval_2:
        st.markdown("#### ğŸ–¼ï¸ æ€§èƒ½å¯¹æ¯”å›¾è°±")
        # åŠ¨æ€åŠ è½½æ–°ç”Ÿæˆçš„å¯¹æ¯”å›¾
        chart_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "paper_assets", "Fig3_ModelCompare_NEW.png")
        if os.path.exists(chart_path):
            st.image(chart_path, caption="å›¾4.1 ä¸åŒæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹æ€§èƒ½å¯¹æ¯”", use_column_width=True)
        else:
            st.warning("âš ï¸ å›¾è¡¨æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥ paper_assets ç›®å½•")

# --- Footer ---
st.markdown("<br><br>", unsafe_allow_html=True)
st.markdown(
    """
    <div style='text-align: center; color: #666; font-size: 12px;'>
        ğŸ“ æ²³æµ·å¤§å­¦Â·æ°´åˆ©å¤§æ•°æ®å’Œä¿¡æ¯æŒ–æ˜æŠ€æœ¯è¯¾ç¨‹è®¾è®¡ | å¼€å‘è€…ï¼šç« æ¶µç¡• (æ™ºæ…§æ°´åˆ©ä¸“ä¸š)
    </div>
    """, 
    unsafe_allow_html=True
)
